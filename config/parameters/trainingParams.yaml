
### ~\config\parameters\configTraining.yaml
targetColName: percentage
epochs : 150
dataLoaderArgs :  {'batch_size': 10, 'num_workers': 4,'drop_last': True}
normalize : False
scheduler: plateau
makeTest: True
hydra: default
override hydra/hydra_logging: colorlog # enable color logging to make it pretty
override hydra/job_logging: colorlog # enable color logging to make it pretty
modelMode: train
# @package _global_
##  Model
model:
  _target_: model_set.models.UNetClassiFlood
  classes : 1
  in_channels : 1
  dropout: True   # (bool) Use dropout or not
  prob: 0.1  # float: 0. - 0.99
  addParams : {patch_W: 384,patch_H: 384, negative_slope_linear: 0.01, negative_slope_Encoder : 0.01}  # Only for UnetClassiFlood
  #classifierOn : False    # Only for UnetFlood
init_weight:
  _partial_: True 
  _target_: torch.nn.init.kaiming_normal_
initWeightParams: {mode:'fan_out', nonlinearity :'relu'}
## Loss
loss_fn:
  _partial_: True 
  _target_: torch.nn.functional.binary_cross_entropy_with_logits # scr.losses.lovasz_hinge #
## Metric
metric_fn :
  _partial_: True 
  _target_: scr.losses.iou_binary 
## Optimizer
optimizer:
  _target_: torch.optim.Adam
  maximize : False
  lr: 0.01
  weight_decay : 0.9