[2023-05-25 13:33:21,878][root][INFO] - Model saved as :2305251333
[2023-05-25 13:33:21,878][root][INFO] - {'_target_': 'model_set.models.UNetFlood', 'classes': 1, 'in_channels': 1, 'dropout': True, 'prob': 0.1}
[2023-05-25 13:33:21,878][root][INFO] - {'_partial_': True, '_target_': 'torch.nn.functional.binary_cross_entropy_with_logits'}
[2023-05-25 13:33:21,879][root][INFO] - {'_target_': 'torch.optim.Adam', 'maximize': False, 'lr': 1e-06, 'weight_decay': 0.9}
[2023-05-25 13:38:37,111][scr.models_trainer][INFO] - Epoch_0: trainLoss = 0.6573877421756614: valLoss = 0.6414795414586763: valMetric = 0.0; test_loss = 0.6076078225848496; testMetric = 0.0
[2023-05-25 13:43:43,779][scr.models_trainer][INFO] - Epoch_1: trainLoss = 0.6454975069009395: valLoss = 0.6617788077149559: valMetric = 0.015239287572948861; test_loss = 0.6254665944524991; testMetric = 0.022114764297024157
[2023-05-25 13:48:51,135][scr.models_trainer][INFO] - Epoch_2: trainLoss = 0.6379952169063349: valLoss = 0.6577495370977487: valMetric = 11.775469712735292; test_loss = 0.6303506227590705; testMetric = 19.032612476430668
[2023-05-25 13:54:47,736][scr.models_trainer][INFO] - Epoch_3: trainLoss = 0.6298327923877552: valLoss = 0.6891970407947823: valMetric = 16.73673511247132; test_loss = 0.7088679950083455; testMetric = 9.34024569239098
[2023-05-25 14:04:01,453][scr.models_trainer][INFO] - Epoch_4: trainLoss = 0.6242070117060156: valLoss = 0.6565579339562349: valMetric = 5.673866403916221; test_loss = 0.6327838950580166; testMetric = 7.543712106388436
[2023-05-25 14:10:49,836][scr.models_trainer][INFO] - Epoch_5: trainLoss = 0.6185463083723624: valLoss = 0.6593999092902371: valMetric = 11.507095160553611; test_loss = 0.6378590980524658; testMetric = 16.237410882690487
[2023-05-25 14:15:55,027][scr.models_trainer][INFO] - Epoch_6: trainLoss = 0.614129564011995: valLoss = 0.6792660453286602: valMetric = 13.833084730974342; test_loss = 0.7101747451290008; testMetric = 9.422538254336297
[2023-05-25 14:21:04,028][scr.models_trainer][INFO] - Epoch_7: trainLoss = 0.6115920373044655: valLoss = 0.747680008973009: valMetric = 16.723932169051103; test_loss = 0.8735005797878388; testMetric = 9.34024569239098
[2023-05-25 14:26:11,047][scr.models_trainer][INFO] - Epoch_8: trainLoss = 0.6078375525453418: valLoss = 0.7566647661952817: valMetric = 16.547481577340783; test_loss = 0.8857902362141558; testMetric = 9.34024569239098
[2023-05-25 14:31:18,082][scr.models_trainer][INFO] - Epoch_9: trainLoss = 0.60428293990948: valLoss = 0.6738620487664213: valMetric = 15.231486436773308; test_loss = 0.6724102580419151; testMetric = 9.343953107897063
[2023-05-25 14:36:33,294][scr.models_trainer][INFO] - Epoch_10: trainLoss = 0.6036509178765943: valLoss = 0.8650838749193067: valMetric = 15.802537226685343; test_loss = 1.1914644901470473; testMetric = 9.34173081206989
[2023-05-25 14:41:43,802][scr.models_trainer][INFO] - Epoch_11: trainLoss = 0.5996621146688081: valLoss = 0.7791001249348098: valMetric = 15.421401061244564; test_loss = 0.9660627755426592; testMetric = 9.340378128471178
[2023-05-25 14:46:53,104][scr.models_trainer][INFO] - Epoch_12: trainLoss = 0.5978434430795723: valLoss = 0.669893142940411: valMetric = 11.293321222377552; test_loss = 0.6845720650688294; testMetric = 9.952231713838268
[2023-05-25 14:52:01,943][scr.models_trainer][INFO] - Epoch_13: trainLoss = 0.5974420121008396: valLoss = 0.6748538642148276: valMetric = 14.05593973345418; test_loss = 0.6966482607587692; testMetric = 9.481042526499492
[2023-05-25 15:01:21,263][scr.models_trainer][INFO] - Epoch_14: trainLoss = 0.5997634509817712: valLoss = 0.6850771946673417: valMetric = 12.905333477841955; test_loss = 0.7394635792701475; testMetric = 10.98849186738781
[2023-05-25 15:07:32,478][scr.models_trainer][INFO] - Epoch_15: trainLoss = 0.5997568030829268: valLoss = 0.6559362581477093: valMetric = 0.0; test_loss = 0.651385266133534; testMetric = 0.0
[2023-05-25 15:16:03,548][scr.models_trainer][INFO] - Epoch_16: trainLoss = 0.6019928803824252: valLoss = 0.6753827686136092: valMetric = 0.0; test_loss = 0.7185880234164577; testMetric = 0.0
[2023-05-25 15:25:30,537][scr.models_trainer][INFO] - Epoch_17: trainLoss = 0.6027453076540104: valLoss = 0.6515552245417432: valMetric = 0.0; test_loss = 0.6410738934752762; testMetric = 0.0
[2023-05-25 15:31:12,877][scr.models_trainer][INFO] - Epoch_18: trainLoss = 0.603540481686416: valLoss = 0.6567868542805988: valMetric = 0.0; test_loss = 0.6333261004058264; testMetric = 0.0
[2023-05-25 15:36:18,207][scr.models_trainer][INFO] - Epoch_19: trainLoss = 0.602850002288114: valLoss = 0.7645715712452653: valMetric = 11.523224363456489; test_loss = 0.9619481762250265; testMetric = 9.546685081631681
[2023-05-25 15:41:20,647][scr.models_trainer][INFO] - Epoch_20: trainLoss = 0.6056362857142439: valLoss = 0.6466256239306387: valMetric = 0.0; test_loss = 0.6176861067933421; testMetric = 0.0
[2023-05-25 15:46:24,557][scr.models_trainer][INFO] - Epoch_21: trainLoss = 0.6065488394993623: valLoss = 0.6398717993542776: valMetric = 0.0; test_loss = 0.6209536318176536; testMetric = 0.0
[2023-05-25 15:51:29,043][scr.models_trainer][INFO] - Epoch_22: trainLoss = 0.6077064799417246: valLoss = 0.6715424094143225: valMetric = 12.38250905059904; test_loss = 0.6960066081054749; testMetric = 10.570280387785571
[2023-05-25 15:56:26,805][scr.models_trainer][INFO] - Epoch_23: trainLoss = 0.6078536743427485: valLoss = 0.6432080656739335: valMetric = 0.0; test_loss = 0.6090652567725028; testMetric = 0.0
[2023-05-25 16:01:27,708][scr.models_trainer][INFO] - Epoch_24: trainLoss = 0.6100157921388195: valLoss = 0.6437949693607325: valMetric = 0.0; test_loss = 0.6327413080200073; testMetric = 0.0
[2023-05-25 16:06:33,598][scr.models_trainer][INFO] - Epoch_25: trainLoss = 0.6124365754634626: valLoss = 0.6359134550819445: valMetric = 0.0; test_loss = 0.604786320238985; testMetric = 0.0
[2023-05-25 16:11:30,516][scr.models_trainer][INFO] - Epoch_26: trainLoss = 0.6140558060726352: valLoss = 0.6377654979426657: valMetric = 0.0; test_loss = 0.6018131599631361; testMetric = 0.0
[2023-05-25 16:16:29,788][scr.models_trainer][INFO] - Epoch_27: trainLoss = 0.6158146104925316: valLoss = 0.6344187099056028: valMetric = 0.0; test_loss = 0.608955406373547; testMetric = 0.0
[2023-05-25 16:25:44,577][scr.models_trainer][INFO] - Epoch_28: trainLoss = 0.6177505112821278: valLoss = 0.632046442759696: valMetric = 0.0; test_loss = 0.5993664679668282; testMetric = 0.0
[2023-05-25 16:36:37,013][scr.models_trainer][INFO] - Epoch_29: trainLoss = 0.6189426916740846: valLoss = 0.6245606086361948: valMetric = 0.0; test_loss = 0.5944419586530296; testMetric = 0.0
[2023-05-25 16:47:39,790][scr.models_trainer][INFO] - Epoch_30: trainLoss = 0.6208499012880875: valLoss = 0.6394002683198632: valMetric = 0.0; test_loss = 0.6095433703032873; testMetric = 0.0
[2023-05-25 16:58:04,061][scr.models_trainer][INFO] - Epoch_31: trainLoss = 0.6242652136254698: valLoss = 0.6205587506893292: valMetric = 0.0; test_loss = 0.5940445549385522; testMetric = 0.0
[2023-05-25 17:05:27,381][scr.models_trainer][INFO] - Epoch_32: trainLoss = 0.6269942538953074: valLoss = 0.6385667984509588: valMetric = 0.0; test_loss = 0.6142134086419178; testMetric = 0.0
[2023-05-25 17:10:20,396][scr.models_trainer][INFO] - Epoch_33: trainLoss = 0.6296964356430876: valLoss = 0.6446814815602709: valMetric = 0.0; test_loss = 0.6304908522995569; testMetric = 0.0
[2023-05-25 17:15:09,863][scr.models_trainer][INFO] - Epoch_34: trainLoss = 0.6313592355219617: valLoss = 0.6449882660678883: valMetric = 0.0; test_loss = 0.6359164842995264; testMetric = 0.0
[2023-05-25 17:19:57,811][scr.models_trainer][INFO] - Epoch_35: trainLoss = 0.6299068989922765: valLoss = 0.6448064665099484: valMetric = 0.0; test_loss = 0.6362696604062152; testMetric = 0.0
[2023-05-25 17:24:51,950][scr.models_trainer][INFO] - Epoch_36: trainLoss = 0.6302216283503804: valLoss = 0.6443442528571316: valMetric = 0.0; test_loss = 0.6357206061322201; testMetric = 0.0
[2023-05-25 17:29:40,993][scr.models_trainer][INFO] - Epoch_37: trainLoss = 0.6295037734983943: valLoss = 0.6438505068496244: valMetric = 0.0; test_loss = 0.6351330203394736; testMetric = 0.0
[2023-05-25 17:34:30,712][scr.models_trainer][INFO] - Epoch_38: trainLoss = 0.6289787954910819: valLoss = 0.6433360064449023: valMetric = 0.0; test_loss = 0.6345205627461915; testMetric = 0.0
[2023-05-25 17:39:18,846][scr.models_trainer][INFO] - Epoch_39: trainLoss = 0.6282620373293427: valLoss = 0.6427929572124577: valMetric = 0.0; test_loss = 0.6338739273368671; testMetric = 0.0
[2023-05-25 17:44:07,744][scr.models_trainer][INFO] - Epoch_40: trainLoss = 0.6278139845131067: valLoss = 0.6422311250288882: valMetric = 0.0; test_loss = 0.6332047472717941; testMetric = 0.0
[2023-05-25 17:48:54,657][scr.models_trainer][INFO] - Epoch_41: trainLoss = 0.6262954007223402: valLoss = 0.6416289746461801: valMetric = 0.0; test_loss = 0.6324873015444766; testMetric = 0.0
[2023-05-25 17:53:47,457][scr.models_trainer][INFO] - Epoch_42: trainLoss = 0.6257348352556215: valLoss = 0.6410180506993778: valMetric = 0.0; test_loss = 0.6317591763311817; testMetric = 0.0
[2023-05-25 17:58:37,450][scr.models_trainer][INFO] - Epoch_43: trainLoss = 0.6248946199565025: valLoss = 0.6403871061813892: valMetric = 0.0; test_loss = 0.6310069349504286; testMetric = 0.0
[2023-05-25 18:03:25,379][scr.models_trainer][INFO] - Epoch_44: trainLoss = 0.6245816271801643: valLoss = 0.6397482258590621: valMetric = 0.0; test_loss = 0.6302449799353077; testMetric = 0.0
[2023-05-25 18:08:13,108][scr.models_trainer][INFO] - Epoch_45: trainLoss = 0.6238358321006753: valLoss = 0.6391010847522984: valMetric = 0.0; test_loss = 0.6294728985396765; testMetric = 0.0
[2023-05-25 18:13:01,807][scr.models_trainer][INFO] - Epoch_46: trainLoss = 0.6230396997629275: valLoss = 0.6384543905306101: valMetric = 0.0; test_loss = 0.6287010664580971; testMetric = 0.0
[2023-05-25 18:17:49,352][scr.models_trainer][INFO] - Epoch_47: trainLoss = 0.6219477462099433: valLoss = 0.63780804285452: valMetric = 0.0; test_loss = 0.6279293772994831; testMetric = 0.0
[2023-05-25 18:22:41,038][scr.models_trainer][INFO] - Epoch_48: trainLoss = 0.6213196262299046: valLoss = 0.6371667379110901: valMetric = 0.0; test_loss = 0.6271634332595333; testMetric = 0.0
[2023-05-25 18:27:30,137][scr.models_trainer][INFO] - Epoch_49: trainLoss = 0.6205812252782824: valLoss = 0.6365342745229826: valMetric = 0.0; test_loss = 0.6264077854412858; testMetric = 0.0
[2023-05-25 18:32:16,500][scr.models_trainer][INFO] - Epoch_50: trainLoss = 0.6201188388391999: valLoss = 0.6359130431659258: valMetric = 0.0; test_loss = 0.6256652724358344; testMetric = 0.0
[2023-05-25 18:37:08,388][scr.models_trainer][INFO] - Epoch_51: trainLoss = 0.6184958477316086: valLoss = 0.6352822286399764: valMetric = 0.0; test_loss = 0.6249110596154326; testMetric = 0.0
[2023-05-25 18:41:55,460][scr.models_trainer][INFO] - Epoch_52: trainLoss = 0.6175473653583442: valLoss = 0.6346564661318334: valMetric = 0.0; test_loss = 0.6241626008864372; testMetric = 0.0
[2023-05-25 18:46:44,382][scr.models_trainer][INFO] - Epoch_53: trainLoss = 0.6172911866024643: valLoss = 0.6340465437826799: valMetric = 0.0; test_loss = 0.6234328484022489; testMetric = 0.0
[2023-05-25 18:51:36,537][scr.models_trainer][INFO] - Epoch_54: trainLoss = 0.6158368161897364: valLoss = 0.6334301053579129: valMetric = 0.0; test_loss = 0.6226950499319261; testMetric = 0.0
[2023-05-25 18:56:32,789][scr.models_trainer][INFO] - Epoch_55: trainLoss = 0.6158473287410539: valLoss = 0.6328361235072265: valMetric = 0.0; test_loss = 0.6219838421831849; testMetric = 0.0
[2023-05-25 19:01:21,333][scr.models_trainer][INFO] - Epoch_56: trainLoss = 0.614382327941179: valLoss = 0.6322331404566166: valMetric = 0.0; test_loss = 0.6212616421843088; testMetric = 0.0
[2023-05-25 19:06:13,515][scr.models_trainer][INFO] - Epoch_57: trainLoss = 0.6148920936105522: valLoss = 0.6316624879837036: valMetric = 0.0; test_loss = 0.6205779057677074; testMetric = 0.0
[2023-05-25 19:11:00,685][scr.models_trainer][INFO] - Epoch_58: trainLoss = 0.6117439978760137: valLoss = 0.6310544574081: valMetric = 0.0; test_loss = 0.6198491454124451; testMetric = 0.0
[2023-05-25 19:15:46,780][scr.models_trainer][INFO] - Epoch_59: trainLoss = 0.6130838940555623: valLoss = 0.6304931595696875: valMetric = 0.0; test_loss = 0.619176152572837; testMetric = 0.0
[2023-05-25 19:20:34,270][scr.models_trainer][INFO] - Epoch_60: trainLoss = 0.6113200525061242: valLoss = 0.6299182904425578: valMetric = 0.0; test_loss = 0.6184866550148175; testMetric = 0.0
[2023-05-25 19:25:28,426][scr.models_trainer][INFO] - Epoch_61: trainLoss = 0.6100050815275184: valLoss = 0.6293357332148145: valMetric = 0.0; test_loss = 0.6177877053137748; testMetric = 0.0
[2023-05-25 19:30:13,919][scr.models_trainer][INFO] - Epoch_62: trainLoss = 0.6091381067891593: valLoss = 0.6287656069999963: valMetric = 0.0; test_loss = 0.61710343053264; testMetric = 0.0
[2023-05-25 19:34:57,357][scr.models_trainer][INFO] - Epoch_63: trainLoss = 0.6084398664611129: valLoss = 0.628203011637357: valMetric = 0.0; test_loss = 0.6164279400661428; testMetric = 0.0
[2023-05-25 19:39:41,092][scr.models_trainer][INFO] - Epoch_64: trainLoss = 0.6079940640415715: valLoss = 0.6276481960287046: valMetric = 0.0; test_loss = 0.615761596669433; testMetric = 0.0
[2023-05-25 19:44:26,367][scr.models_trainer][INFO] - Epoch_65: trainLoss = 0.6064152278963537: valLoss = 0.6270836864284535: valMetric = 0.0; test_loss = 0.6150833496483423; testMetric = 0.0
[2023-05-25 19:49:09,349][scr.models_trainer][INFO] - Epoch_66: trainLoss = 0.6066394797103972: valLoss = 0.6265482603006027: valMetric = 0.0; test_loss = 0.6144398335487612; testMetric = 0.0
[2023-05-25 19:53:57,237][scr.models_trainer][INFO] - Epoch_67: trainLoss = 0.6061016740087568: valLoss = 0.6260233674217109: valMetric = 0.0; test_loss = 0.6138087639244654; testMetric = 0.0
[2023-05-25 19:58:40,162][scr.models_trainer][INFO] - Epoch_68: trainLoss = 0.605604450019459: valLoss = 0.6255037859456622: valMetric = 0.0; test_loss = 0.6131838931832262; testMetric = 0.0
[2023-05-25 20:03:23,860][scr.models_trainer][INFO] - Epoch_69: trainLoss = 0.6043227238352225: valLoss = 0.6249827017736196: valMetric = 0.0; test_loss = 0.6125570067795374; testMetric = 0.0
[2023-05-25 20:08:11,368][scr.models_trainer][INFO] - Epoch_70: trainLoss = 0.6035833579926935: valLoss = 0.6244609239113391: valMetric = 0.0; test_loss = 0.6119290737695592; testMetric = 0.0
[2023-05-25 20:12:55,698][scr.models_trainer][INFO] - Epoch_71: trainLoss = 0.6033686481691357: valLoss = 0.6239595673791128: valMetric = 0.0; test_loss = 0.6113255036774502; testMetric = 0.0
[2023-05-25 20:17:37,609][scr.models_trainer][INFO] - Epoch_72: trainLoss = 0.6019130117784046: valLoss = 0.6234536988651334: valMetric = 0.0; test_loss = 0.6107163557442286; testMetric = 0.0
[2023-05-25 20:22:24,691][scr.models_trainer][INFO] - Epoch_73: trainLoss = 0.6010784185619439: valLoss = 0.6229503804714835: valMetric = 0.0; test_loss = 0.6101100387111786; testMetric = 0.0
[2023-05-25 20:27:07,710][scr.models_trainer][INFO] - Epoch_74: trainLoss = 0.6006363077741254: valLoss = 0.6224562615605455: valMetric = 0.0; test_loss = 0.6095146133053687; testMetric = 0.0
[2023-05-25 20:31:51,386][scr.models_trainer][INFO] - Epoch_75: trainLoss = 0.6002857672058849: valLoss = 0.6219787540747292: valMetric = 0.0; test_loss = 0.6089390439371909; testMetric = 0.0
[2023-05-25 20:36:34,077][scr.models_trainer][INFO] - Epoch_76: trainLoss = 0.6005025587370688: valLoss = 0.6215187074551031: valMetric = 0.0; test_loss = 0.6083843310674032; testMetric = 0.0
[2023-05-25 20:41:20,757][scr.models_trainer][INFO] - Epoch_77: trainLoss = 0.5995935654182378: valLoss = 0.6210621053249992: valMetric = 0.0; test_loss = 0.6078336213224678; testMetric = 0.0
[2023-05-25 20:46:05,056][scr.models_trainer][INFO] - Epoch_78: trainLoss = 0.5982165978085167: valLoss = 0.6205898978602347: valMetric = 0.0; test_loss = 0.6072639079504115; testMetric = 0.0
[2023-05-25 20:50:47,991][scr.models_trainer][INFO] - Epoch_79: trainLoss = 0.5983374868925424: valLoss = 0.6201423888829485: valMetric = 0.0; test_loss = 0.606723827059551; testMetric = 0.0
[2023-05-25 20:55:36,080][scr.models_trainer][INFO] - Epoch_80: trainLoss = 0.596631518283658: valLoss = 0.6196870926636547: valMetric = 0.0; test_loss = 0.6061742023755146; testMetric = 0.0
[2023-05-25 21:00:22,236][scr.models_trainer][INFO] - Epoch_81: trainLoss = 0.5973326310801541: valLoss = 0.6192625197932948: valMetric = 0.0; test_loss = 0.6056615094984731; testMetric = 0.0
[2023-05-25 21:05:16,322][scr.models_trainer][INFO] - Epoch_82: trainLoss = 0.5971025351231348: valLoss = 0.6188524955481141: valMetric = 0.0; test_loss = 0.6051662333549992; testMetric = 0.0
[2023-05-25 21:10:05,445][scr.models_trainer][INFO] - Epoch_83: trainLoss = 0.5957079037605748: valLoss = 0.6184346283500518: valMetric = 0.0; test_loss = 0.6046613538137047; testMetric = 0.0
[2023-05-25 21:14:49,568][scr.models_trainer][INFO] - Epoch_84: trainLoss = 0.5948967690481921: valLoss = 0.6180164852933069: valMetric = 0.0; test_loss = 0.6041559942307011; testMetric = 0.0
[2023-05-25 21:19:31,700][scr.models_trainer][INFO] - Epoch_85: trainLoss = 0.5941217525670941: valLoss = 0.6175994079316681: valMetric = 0.0; test_loss = 0.6036517652132178; testMetric = 0.0
[2023-05-25 21:24:21,192][scr.models_trainer][INFO] - Epoch_86: trainLoss = 0.5940838993211969: valLoss = 0.617197622006862: valMetric = 0.0; test_loss = 0.6031659200627316; testMetric = 0.0
[2023-05-25 21:29:07,161][scr.models_trainer][INFO] - Epoch_87: trainLoss = 0.5927871800419852: valLoss = 0.6167872086841257: valMetric = 0.0; test_loss = 0.6026695011764445; testMetric = 0.0
[2023-05-25 21:33:49,686][scr.models_trainer][INFO] - Epoch_88: trainLoss = 0.5933582682553211: valLoss = 0.6163985016357959: valMetric = 0.0; test_loss = 0.602199198097311; testMetric = 0.0
[2023-05-25 21:38:35,943][scr.models_trainer][INFO] - Epoch_89: trainLoss = 0.5926737145976091: valLoss = 0.6160220653567482: valMetric = 0.0; test_loss = 0.6017436058290543; testMetric = 0.0
[2023-05-25 21:43:19,875][scr.models_trainer][INFO] - Epoch_90: trainLoss = 0.5919915963310963: valLoss = 0.6156466723087445: valMetric = 0.0; test_loss = 0.6012891652763531; testMetric = 0.0
[2023-05-25 21:48:02,394][scr.models_trainer][INFO] - Epoch_91: trainLoss = 0.5900745198856957: valLoss = 0.615253068993439: valMetric = 0.0; test_loss = 0.6008125799958424; testMetric = 0.0
[2023-05-25 21:52:48,073][scr.models_trainer][INFO] - Epoch_92: trainLoss = 0.5910593290976971: valLoss = 0.6148915075177523: valMetric = 0.0; test_loss = 0.6003746608252166; testMetric = 0.0
[2023-05-25 21:57:33,562][scr.models_trainer][INFO] - Epoch_93: trainLoss = 0.5906793569356336: valLoss = 0.6145363099610985: valMetric = 0.0; test_loss = 0.5999443223399501; testMetric = 0.0
[2023-05-25 22:02:20,568][scr.models_trainer][INFO] - Epoch_94: trainLoss = 0.5902860195633227: valLoss = 0.6141914937963437: valMetric = 0.0; test_loss = 0.5995264745527699; testMetric = 0.0
[2023-05-25 22:07:02,857][scr.models_trainer][INFO] - Epoch_95: trainLoss = 0.5897658484020825: valLoss = 0.6138527902526472: valMetric = 0.0; test_loss = 0.5991159100686351; testMetric = 0.0
[2023-05-25 22:11:51,734][scr.models_trainer][INFO] - Epoch_96: trainLoss = 0.5891722399867972: valLoss = 0.6135158442971694: valMetric = 0.0; test_loss = 0.5987074285425166; testMetric = 0.0
[2023-05-25 22:16:45,821][scr.models_trainer][INFO] - Epoch_97: trainLoss = 0.5886863877361247: valLoss = 0.6131827238217071: valMetric = 0.0; test_loss = 0.5983034538966353; testMetric = 0.0
[2023-05-25 22:21:37,769][scr.models_trainer][INFO] - Epoch_98: trainLoss = 0.5877521266789345: valLoss = 0.6128485421439511: valMetric = 0.0; test_loss = 0.5978981070621039; testMetric = 0.0
[2023-05-25 22:26:22,703][scr.models_trainer][INFO] - Epoch_99: trainLoss = 0.587682719984294: valLoss = 0.6125287985681889: valMetric = 0.0; test_loss = 0.5975101827293314; testMetric = 0.0
[2023-05-25 22:31:09,541][scr.models_trainer][INFO] - Epoch_100: trainLoss = 0.5867177726951273: valLoss = 0.6122010473030896: valMetric = 0.0; test_loss = 0.5971124268347218; testMetric = 0.0
[2023-05-25 22:35:51,657][scr.models_trainer][INFO] - Epoch_101: trainLoss = 0.5876674781697891: valLoss = 0.611905560721105: valMetric = 0.0; test_loss = 0.5967537965825809; testMetric = 0.0
[2023-05-25 22:40:38,596][scr.models_trainer][INFO] - Epoch_102: trainLoss = 0.5864055643405661: valLoss = 0.6116036083830062: valMetric = 0.0; test_loss = 0.5963871825125909; testMetric = 0.0
[2023-05-25 22:45:22,308][scr.models_trainer][INFO] - Epoch_103: trainLoss = 0.5854631848314136: valLoss = 0.6112926302842758: valMetric = 0.0; test_loss = 0.5960095601697122; testMetric = 0.0
[2023-05-25 22:50:05,026][scr.models_trainer][INFO] - Epoch_104: trainLoss = 0.5867586672570188: valLoss = 0.6110165406711138: valMetric = 0.0; test_loss = 0.5956742282836668; testMetric = 0.0
[2023-05-25 22:54:52,147][scr.models_trainer][INFO] - Epoch_105: trainLoss = 0.5846444929896288: valLoss = 0.6107197748356729: valMetric = 0.0; test_loss = 0.5953136926056236; testMetric = 0.0
[2023-05-25 22:59:37,292][scr.models_trainer][INFO] - Epoch_106: trainLoss = 0.5854072264589623: valLoss = 0.6104457983419523: valMetric = 0.0; test_loss = 0.5949807846417992; testMetric = 0.0
[2023-05-25 23:04:19,568][scr.models_trainer][INFO] - Epoch_107: trainLoss = 0.5853773840597144: valLoss = 0.6101821604086526: valMetric = 0.0; test_loss = 0.5946603833988149; testMetric = 0.0
[2023-05-25 23:09:06,654][scr.models_trainer][INFO] - Epoch_108: trainLoss = 0.5829292126209028: valLoss = 0.6098912747661073: valMetric = 0.0; test_loss = 0.5943067855732416; testMetric = 0.0
[2023-05-25 23:13:50,616][scr.models_trainer][INFO] - Epoch_109: trainLoss = 0.5843300422854403: valLoss = 0.6096341196616092: valMetric = 0.0; test_loss = 0.5939941060158515; testMetric = 0.0
[2023-05-25 23:18:32,514][scr.models_trainer][INFO] - Epoch_110: trainLoss = 0.5825826384468304: valLoss = 0.6093595600008366: valMetric = 0.0; test_loss = 0.593660230277687; testMetric = 0.0
[2023-05-25 23:23:19,078][scr.models_trainer][INFO] - Epoch_111: trainLoss = 0.5826343311692974: valLoss = 0.6090954835690445: valMetric = 0.0; test_loss = 0.5933390387924768; testMetric = 0.0
[2023-05-25 23:28:02,533][scr.models_trainer][INFO] - Epoch_112: trainLoss = 0.5830912857323313: valLoss = 0.6088526563428754: valMetric = 0.0; test_loss = 0.5930436195865754; testMetric = 0.0
[2023-05-25 23:32:44,808][scr.models_trainer][INFO] - Epoch_113: trainLoss = 0.582343799078306: valLoss = 0.6086043628615949: valMetric = 0.0; test_loss = 0.5927414849240292; testMetric = 0.0
[2023-05-25 23:37:27,013][scr.models_trainer][INFO] - Epoch_114: trainLoss = 0.5814973685026521: valLoss = 0.6083516044233312: valMetric = 0.0; test_loss = 0.5924338909887499; testMetric = 0.0
[2023-05-25 23:42:15,909][scr.models_trainer][INFO] - Epoch_115: trainLoss = 0.5830102088884553: valLoss = 0.6081335589514306: valMetric = 0.0; test_loss = 0.5921684849646783; testMetric = 0.0
[2023-05-25 23:46:58,800][scr.models_trainer][INFO] - Epoch_116: trainLoss = 0.5802557397276119: valLoss = 0.607882956464087: valMetric = 0.0; test_loss = 0.5918633982699405; testMetric = 0.0
[2023-05-25 23:51:41,315][scr.models_trainer][INFO] - Epoch_117: trainLoss = 0.5799802605651506: valLoss = 0.6076387993654414: valMetric = 0.0; test_loss = 0.591566083251789; testMetric = 0.0
[2023-05-25 23:56:28,859][scr.models_trainer][INFO] - Epoch_118: trainLoss = 0.5806514756894359: valLoss = 0.6074117461041589: valMetric = 0.0; test_loss = 0.5912895535910001; testMetric = 0.0
[2023-05-26 00:01:12,555][scr.models_trainer][INFO] - Epoch_119: trainLoss = 0.5811451990460011: valLoss = 0.6072033700631492: valMetric = 0.0; test_loss = 0.591035718558937; testMetric = 0.0
[2023-05-26 00:05:55,071][scr.models_trainer][INFO] - Epoch_120: trainLoss = 0.5798614027228982: valLoss = 0.6069888418643319: valMetric = 0.0; test_loss = 0.5907743739825423; testMetric = 0.0
[2023-05-26 00:10:42,385][scr.models_trainer][INFO] - Epoch_121: trainLoss = 0.5797202041969693: valLoss = 0.6067778474122436: valMetric = 0.0; test_loss = 0.5905172722313994; testMetric = 0.0
[2023-05-26 00:15:27,524][scr.models_trainer][INFO] - Epoch_122: trainLoss = 0.5796366701802264: valLoss = 0.6065735181971411: valMetric = 0.0; test_loss = 0.5902682824801373; testMetric = 0.0
[2023-05-26 00:20:09,214][scr.models_trainer][INFO] - Epoch_123: trainLoss = 0.5795082145462712: valLoss = 0.6063764248062019: valMetric = 0.0; test_loss = 0.5900280475616455; testMetric = 0.0
[2023-05-26 00:24:53,926][scr.models_trainer][INFO] - Epoch_124: trainLoss = 0.5786089094562051: valLoss = 0.6061740805156267: valMetric = 0.0; test_loss = 0.5897813759824281; testMetric = 0.0
[2023-05-26 00:29:37,211][scr.models_trainer][INFO] - Epoch_125: trainLoss = 0.5797787656812231: valLoss = 0.605997585471551: valMetric = 0.0; test_loss = 0.5895661942420467; testMetric = 0.0
[2023-05-26 00:34:19,952][scr.models_trainer][INFO] - Epoch_126: trainLoss = 0.578843064656814: valLoss = 0.6058134047230285: valMetric = 0.0; test_loss = 0.5893416026587127; testMetric = 0.0
[2023-05-26 00:39:07,269][scr.models_trainer][INFO] - Epoch_127: trainLoss = 0.5780524736317081: valLoss = 0.6056225859939154: valMetric = 0.0; test_loss = 0.5891088894618455; testMetric = 0.0
[2023-05-26 00:43:50,730][scr.models_trainer][INFO] - Epoch_128: trainLoss = 0.5779802883745473: valLoss = 0.6054389138317587: valMetric = 0.0; test_loss = 0.5888848580339904; testMetric = 0.0
[2023-05-26 00:48:33,056][scr.models_trainer][INFO] - Epoch_129: trainLoss = 0.5776211756547057: valLoss = 0.6052591483197619: valMetric = 0.0; test_loss = 0.588665537295803; testMetric = 0.0
[2023-05-26 00:53:19,828][scr.models_trainer][INFO] - Epoch_130: trainLoss = 0.5782424422979707: valLoss = 0.6050967178752075: valMetric = 0.0; test_loss = 0.5884673524928349; testMetric = 0.0
[2023-05-26 00:58:05,074][scr.models_trainer][INFO] - Epoch_131: trainLoss = 0.5781079663483748: valLoss = 0.6049368237730247: valMetric = 0.0; test_loss = 0.5882722549541022; testMetric = 0.0
[2023-05-26 01:02:48,774][scr.models_trainer][INFO] - Epoch_132: trainLoss = 0.5777002438132485: valLoss = 0.6047782298907562: valMetric = 0.0; test_loss = 0.5880786943179305; testMetric = 0.0
[2023-05-26 01:07:31,328][scr.models_trainer][INFO] - Epoch_133: trainLoss = 0.5763713936157734: valLoss = 0.6046071675554592: valMetric = 0.0; test_loss = 0.5878699197564073; testMetric = 0.0
[2023-05-26 01:12:19,632][scr.models_trainer][INFO] - Epoch_134: trainLoss = 0.5760971777372206: valLoss = 0.6044383123891437: valMetric = 0.0; test_loss = 0.5876637915129302; testMetric = 0.0
[2023-05-26 01:17:01,914][scr.models_trainer][INFO] - Epoch_135: trainLoss = 0.5772019737756411: valLoss = 0.6042938112613544: valMetric = 0.0; test_loss = 0.5874873745825983; testMetric = 0.0
[2023-05-26 01:21:43,113][scr.models_trainer][INFO] - Epoch_136: trainLoss = 0.577290600089238: valLoss = 0.6041565624313738: valMetric = 0.0; test_loss = 0.5873198022124588; testMetric = 0.0
[2023-05-26 01:26:30,175][scr.models_trainer][INFO] - Epoch_137: trainLoss = 0.5745431063094203: valLoss = 0.6039864969013924: valMetric = 0.0; test_loss = 0.5871121050209127; testMetric = 0.0
[2023-05-26 01:31:13,087][scr.models_trainer][INFO] - Epoch_138: trainLoss = 0.5749622592897852: valLoss = 0.603824550482496: valMetric = 0.0; test_loss = 0.5869143310413566; testMetric = 0.0
[2023-05-26 01:35:55,578][scr.models_trainer][INFO] - Epoch_139: trainLoss = 0.5763390530511583: valLoss = 0.6036891377151911: valMetric = 0.0; test_loss = 0.5867489300748353; testMetric = 0.0
[2023-05-26 01:40:41,872][scr.models_trainer][INFO] - Epoch_140: trainLoss = 0.5752867928635951: valLoss = 0.6035442463117628: valMetric = 0.0; test_loss = 0.5865719305571689; testMetric = 0.0
[2023-05-26 01:45:24,986][scr.models_trainer][INFO] - Epoch_141: trainLoss = 0.5759209749089386: valLoss = 0.603414876676684: valMetric = 0.0; test_loss = 0.5864138859574513; testMetric = 0.0
[2023-05-26 01:50:07,693][scr.models_trainer][INFO] - Epoch_142: trainLoss = 0.5749641969777984: valLoss = 0.6032793587775686: valMetric = 0.0; test_loss = 0.5862482946406129; testMetric = 0.0
[2023-05-26 01:54:54,456][scr.models_trainer][INFO] - Epoch_143: trainLoss = 0.5751236435581697: valLoss = 0.6031506621657904: valMetric = 0.0; test_loss = 0.5860910268240077; testMetric = 0.0
[2023-05-26 01:59:37,759][scr.models_trainer][INFO] - Epoch_144: trainLoss = 0.5733512870670245: valLoss = 0.603002047418949: valMetric = 0.0; test_loss = 0.585909394807713; testMetric = 0.0
[2023-05-26 02:04:19,679][scr.models_trainer][INFO] - Epoch_145: trainLoss = 0.5740770062808624: valLoss = 0.6028686096919841: valMetric = 0.0; test_loss = 0.5857462998359434; testMetric = 0.0
[2023-05-26 02:09:06,373][scr.models_trainer][INFO] - Epoch_146: trainLoss = 0.5744209465635404: valLoss = 0.6027472824906585: valMetric = 0.0; test_loss = 0.5855979925842696; testMetric = 0.0
[2023-05-26 02:13:49,704][scr.models_trainer][INFO] - Epoch_147: trainLoss = 0.5735411174012076: valLoss = 0.602617943406704: valMetric = 0.0; test_loss = 0.5854398768435243; testMetric = 0.0
[2023-05-26 02:18:31,366][scr.models_trainer][INFO] - Epoch_148: trainLoss = 0.5738044049750403: valLoss = 0.6024964814210058: valMetric = 0.0; test_loss = 0.5852913625778691; testMetric = 0.0
[2023-05-26 02:23:14,093][scr.models_trainer][INFO] - Epoch_149: trainLoss = 0.5738272903412801: valLoss = 0.6023804455546279: valMetric = 0.0; test_loss = 0.5851494836550887; testMetric = 0.0
[2023-05-26 02:23:14,105][scr.models_trainer][INFO] - Train losses after 150 epochs : [0.6573877421756614, 0.6454975069009395, 0.6379952169063349, 0.6298327923877552, 0.6242070117060156, 0.6185463083723624, 0.614129564011995, 0.6115920373044655, 0.6078375525453418, 0.60428293990948, 0.6036509178765943, 0.5996621146688081, 0.5978434430795723, 0.5974420121008396, 0.5997634509817712, 0.5997568030829268, 0.6019928803824252, 0.6027453076540104, 0.603540481686416, 0.602850002288114, 0.6056362857142439, 0.6065488394993623, 0.6077064799417246, 0.6078536743427485, 0.6100157921388195, 0.6124365754634626, 0.6140558060726352, 0.6158146104925316, 0.6177505112821278, 0.6189426916740846, 0.6208499012880875, 0.6242652136254698, 0.6269942538953074, 0.6296964356430876, 0.6313592355219617, 0.6299068989922765, 0.6302216283503804, 0.6295037734983943, 0.6289787954910819, 0.6282620373293427, 0.6278139845131067, 0.6262954007223402, 0.6257348352556215, 0.6248946199565025, 0.6245816271801643, 0.6238358321006753, 0.6230396997629275, 0.6219477462099433, 0.6213196262299046, 0.6205812252782824, 0.6201188388391999, 0.6184958477316086, 0.6175473653583442, 0.6172911866024643, 0.6158368161897364, 0.6158473287410539, 0.614382327941179, 0.6148920936105522, 0.6117439978760137, 0.6130838940555623, 0.6113200525061242, 0.6100050815275184, 0.6091381067891593, 0.6084398664611129, 0.6079940640415715, 0.6064152278963537, 0.6066394797103972, 0.6061016740087568, 0.605604450019459, 0.6043227238352225, 0.6035833579926935, 0.6033686481691357, 0.6019130117784046, 0.6010784185619439, 0.6006363077741254, 0.6002857672058849, 0.6005025587370688, 0.5995935654182378, 0.5982165978085167, 0.5983374868925424, 0.596631518283658, 0.5973326310801541, 0.5971025351231348, 0.5957079037605748, 0.5948967690481921, 0.5941217525670941, 0.5940838993211969, 0.5927871800419852, 0.5933582682553211, 0.5926737145976091, 0.5919915963310963, 0.5900745198856957, 0.5910593290976971, 0.5906793569356336, 0.5902860195633227, 0.5897658484020825, 0.5891722399867972, 0.5886863877361247, 0.5877521266789345, 0.587682719984294, 0.5867177726951273, 0.5876674781697891, 0.5864055643405661, 0.5854631848314136, 0.5867586672570188, 0.5846444929896288, 0.5854072264589623, 0.5853773840597144, 0.5829292126209028, 0.5843300422854403, 0.5825826384468304, 0.5826343311692974, 0.5830912857323313, 0.582343799078306, 0.5814973685026521, 0.5830102088884553, 0.5802557397276119, 0.5799802605651506, 0.5806514756894359, 0.5811451990460011, 0.5798614027228982, 0.5797202041969693, 0.5796366701802264, 0.5795082145462712, 0.5786089094562051, 0.5797787656812231, 0.578843064656814, 0.5780524736317081, 0.5779802883745473, 0.5776211756547057, 0.5782424422979707, 0.5781079663483748, 0.5777002438132485, 0.5763713936157734, 0.5760971777372206, 0.5772019737756411, 0.577290600089238, 0.5745431063094203, 0.5749622592897852, 0.5763390530511583, 0.5752867928635951, 0.5759209749089386, 0.5749641969777984, 0.5751236435581697, 0.5733512870670245, 0.5740770062808624, 0.5744209465635404, 0.5735411174012076, 0.5738044049750403, 0.5738272903412801]
[2023-05-26 02:23:14,108][scr.models_trainer][INFO] - Validation losses after 150 epochs : [0.6414795414586763, 0.6617788077149559, 0.6577495370977487, 0.6891970407947823, 0.6565579339562349, 0.6593999092902371, 0.6792660453286602, 0.747680008973009, 0.7566647661952817, 0.6738620487664213, 0.8650838749193067, 0.7791001249348098, 0.669893142940411, 0.6748538642148276, 0.6850771946673417, 0.6559362581477093, 0.6753827686136092, 0.6515552245417432, 0.6567868542805988, 0.7645715712452653, 0.6466256239306387, 0.6398717993542776, 0.6715424094143225, 0.6432080656739335, 0.6437949693607325, 0.6359134550819445, 0.6377654979426657, 0.6344187099056028, 0.632046442759696, 0.6245606086361948, 0.6394002683198632, 0.6205587506893292, 0.6385667984509588, 0.6446814815602709, 0.6449882660678883, 0.6448064665099484, 0.6443442528571316, 0.6438505068496244, 0.6433360064449023, 0.6427929572124577, 0.6422311250288882, 0.6416289746461801, 0.6410180506993778, 0.6403871061813892, 0.6397482258590621, 0.6391010847522984, 0.6384543905306101, 0.63780804285452, 0.6371667379110901, 0.6365342745229826, 0.6359130431659258, 0.6352822286399764, 0.6346564661318334, 0.6340465437826799, 0.6334301053579129, 0.6328361235072265, 0.6322331404566166, 0.6316624879837036, 0.6310544574081, 0.6304931595696875, 0.6299182904425578, 0.6293357332148145, 0.6287656069999963, 0.628203011637357, 0.6276481960287046, 0.6270836864284535, 0.6265482603006027, 0.6260233674217109, 0.6255037859456622, 0.6249827017736196, 0.6244609239113391, 0.6239595673791128, 0.6234536988651334, 0.6229503804714835, 0.6224562615605455, 0.6219787540747292, 0.6215187074551031, 0.6210621053249992, 0.6205898978602347, 0.6201423888829485, 0.6196870926636547, 0.6192625197932948, 0.6188524955481141, 0.6184346283500518, 0.6180164852933069, 0.6175994079316681, 0.617197622006862, 0.6167872086841257, 0.6163985016357959, 0.6160220653567482, 0.6156466723087445, 0.615253068993439, 0.6148915075177523, 0.6145363099610985, 0.6141914937963437, 0.6138527902526472, 0.6135158442971694, 0.6131827238217071, 0.6128485421439511, 0.6125287985681889, 0.6122010473030896, 0.611905560721105, 0.6116036083830062, 0.6112926302842758, 0.6110165406711138, 0.6107197748356729, 0.6104457983419523, 0.6101821604086526, 0.6098912747661073, 0.6096341196616092, 0.6093595600008366, 0.6090954835690445, 0.6088526563428754, 0.6086043628615949, 0.6083516044233312, 0.6081335589514306, 0.607882956464087, 0.6076387993654414, 0.6074117461041589, 0.6072033700631492, 0.6069888418643319, 0.6067778474122436, 0.6065735181971411, 0.6063764248062019, 0.6061740805156267, 0.605997585471551, 0.6058134047230285, 0.6056225859939154, 0.6054389138317587, 0.6052591483197619, 0.6050967178752075, 0.6049368237730247, 0.6047782298907562, 0.6046071675554592, 0.6044383123891437, 0.6042938112613544, 0.6041565624313738, 0.6039864969013924, 0.603824550482496, 0.6036891377151911, 0.6035442463117628, 0.603414876676684, 0.6032793587775686, 0.6031506621657904, 0.603002047418949, 0.6028686096919841, 0.6027472824906585, 0.602617943406704, 0.6024964814210058, 0.6023804455546279]
[2023-05-26 02:23:14,112][scr.models_trainer][INFO] - Validation metrics in 150 epochs : [0.0, 0.015239287572948861, 11.775469712735292, 16.73673511247132, 5.673866403916221, 11.507095160553611, 13.833084730974342, 16.723932169051103, 16.547481577340783, 15.231486436773308, 15.802537226685343, 15.421401061244564, 11.293321222377552, 14.05593973345418, 12.905333477841955, 0.0, 0.0, 0.0, 0.0, 11.523224363456489, 0.0, 0.0, 12.38250905059904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2023-05-26 02:23:14,113][scr.models_trainer][INFO] - Test losses after 150 epochs : [0.6076078225848496, 0.6254665944524991, 0.6303506227590705, 0.7088679950083455, 0.6327838950580166, 0.6378590980524658, 0.7101747451290008, 0.8735005797878388, 0.8857902362141558, 0.6724102580419151, 1.1914644901470473, 0.9660627755426592, 0.6845720650688294, 0.6966482607587692, 0.7394635792701475, 0.651385266133534, 0.7185880234164577, 0.6410738934752762, 0.6333261004058264, 0.9619481762250265, 0.6176861067933421, 0.6209536318176536, 0.6960066081054749, 0.6090652567725028, 0.6327413080200073, 0.604786320238985, 0.6018131599631361, 0.608955406373547, 0.5993664679668282, 0.5944419586530296, 0.6095433703032873, 0.5940445549385522, 0.6142134086419178, 0.6304908522995569, 0.6359164842995264, 0.6362696604062152, 0.6357206061322201, 0.6351330203394736, 0.6345205627461915, 0.6338739273368671, 0.6332047472717941, 0.6324873015444766, 0.6317591763311817, 0.6310069349504286, 0.6302449799353077, 0.6294728985396765, 0.6287010664580971, 0.6279293772994831, 0.6271634332595333, 0.6264077854412858, 0.6256652724358344, 0.6249110596154326, 0.6241626008864372, 0.6234328484022489, 0.6226950499319261, 0.6219838421831849, 0.6212616421843088, 0.6205779057677074, 0.6198491454124451, 0.619176152572837, 0.6184866550148175, 0.6177877053137748, 0.61710343053264, 0.6164279400661428, 0.615761596669433, 0.6150833496483423, 0.6144398335487612, 0.6138087639244654, 0.6131838931832262, 0.6125570067795374, 0.6119290737695592, 0.6113255036774502, 0.6107163557442286, 0.6101100387111786, 0.6095146133053687, 0.6089390439371909, 0.6083843310674032, 0.6078336213224678, 0.6072639079504115, 0.606723827059551, 0.6061742023755146, 0.6056615094984731, 0.6051662333549992, 0.6046613538137047, 0.6041559942307011, 0.6036517652132178, 0.6031659200627316, 0.6026695011764445, 0.602199198097311, 0.6017436058290543, 0.6012891652763531, 0.6008125799958424, 0.6003746608252166, 0.5999443223399501, 0.5995264745527699, 0.5991159100686351, 0.5987074285425166, 0.5983034538966353, 0.5978981070621039, 0.5975101827293314, 0.5971124268347218, 0.5967537965825809, 0.5963871825125909, 0.5960095601697122, 0.5956742282836668, 0.5953136926056236, 0.5949807846417992, 0.5946603833988149, 0.5943067855732416, 0.5939941060158515, 0.593660230277687, 0.5933390387924768, 0.5930436195865754, 0.5927414849240292, 0.5924338909887499, 0.5921684849646783, 0.5918633982699405, 0.591566083251789, 0.5912895535910001, 0.591035718558937, 0.5907743739825423, 0.5905172722313994, 0.5902682824801373, 0.5900280475616455, 0.5897813759824281, 0.5895661942420467, 0.5893416026587127, 0.5891088894618455, 0.5888848580339904, 0.588665537295803, 0.5884673524928349, 0.5882722549541022, 0.5880786943179305, 0.5878699197564073, 0.5876637915129302, 0.5874873745825983, 0.5873198022124588, 0.5871121050209127, 0.5869143310413566, 0.5867489300748353, 0.5865719305571689, 0.5864138859574513, 0.5862482946406129, 0.5860910268240077, 0.585909394807713, 0.5857462998359434, 0.5855979925842696, 0.5854398768435243, 0.5852913625778691, 0.5851494836550887]
[2023-05-26 02:23:14,115][scr.models_trainer][INFO] - Test metrics in 150 epochs : [0.0, 0.022114764297024157, 19.032612476430668, 9.34024569239098, 7.543712106388436, 16.237410882690487, 9.422538254336297, 9.34024569239098, 9.34024569239098, 9.343953107897063, 9.34173081206989, 9.340378128471178, 9.952231713838268, 9.481042526499492, 10.98849186738781, 0.0, 0.0, 0.0, 0.0, 9.546685081631681, 0.0, 0.0, 10.570280387785571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
