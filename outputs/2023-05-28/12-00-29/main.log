[2023-05-28 12:00:29,430][root][INFO] - Model saved as :2305281200
[2023-05-28 12:00:29,430][root][INFO] - {'_target_': 'model_set.models.UNetFlood', 'classes': 1, 'in_channels': 1, 'dropout': True, 'prob': 0.1}
[2023-05-28 12:00:29,430][root][INFO] - {'_partial_': True, '_target_': 'torch.nn.functional.binary_cross_entropy_with_logits'}
[2023-05-28 12:00:29,431][root][INFO] - {'_target_': 'torch.optim.Adam', 'maximize': False, 'lr': 1e-05, 'weight_decay': 0.9}
[2023-05-28 12:05:20,135][scr.models_trainer][INFO] - Epoch_0: trainLoss = 0.5560465520470674: valLoss = 0.005861521322524699: valMetric = 0.0; test_loss = 0.002249801598560636; testMetric = 0.0
[2023-05-28 12:09:57,845][scr.models_trainer][INFO] - Epoch_1: trainLoss = 0.365868284061353: valLoss = 0.0049021189698034515: valMetric = 0.0; test_loss = 0.0035559257526221054; testMetric = 0.0
[2023-05-28 12:14:38,536][scr.models_trainer][INFO] - Epoch_2: trainLoss = 0.32543041541225975: valLoss = 0.002745065971259519: valMetric = 0.0; test_loss = 0.0021709717593596427; testMetric = 0.0
[2023-05-28 12:19:13,462][scr.models_trainer][INFO] - Epoch_3: trainLoss = 0.32522642182810796: valLoss = 0.005506836893458163: valMetric = 0.0; test_loss = 0.004332310653426835; testMetric = 0.0
[2023-05-28 12:23:49,218][scr.models_trainer][INFO] - Epoch_4: trainLoss = 0.3261922069213063: valLoss = 0.0031738489001624324: valMetric = 0.0; test_loss = 0.0015720960869383747; testMetric = 0.0
[2023-05-28 12:28:31,475][scr.models_trainer][INFO] - Epoch_5: trainLoss = 0.33015773175298024: valLoss = 0.0027164729253854603: valMetric = 0.0; test_loss = 0.001576568050246175; testMetric = 0.0
[2023-05-28 12:33:10,238][scr.models_trainer][INFO] - Epoch_6: trainLoss = 0.33805856910730925: valLoss = 0.00314520945525073: valMetric = 0.0; test_loss = 0.002309949409062674; testMetric = 0.0
[2023-05-28 12:37:45,939][scr.models_trainer][INFO] - Epoch_7: trainLoss = 0.3478122403209636: valLoss = 0.0062653290413655855: valMetric = 0.0; test_loss = 0.004807981943789248; testMetric = 0.0
[2023-05-28 12:42:22,416][scr.models_trainer][INFO] - Epoch_8: trainLoss = 0.3580825882921191: valLoss = 0.005147626421247005: valMetric = 0.0; test_loss = 0.0040456208150698655; testMetric = 0.0
[2023-05-28 12:47:00,551][scr.models_trainer][INFO] - Epoch_9: trainLoss = 0.37153013622390996: valLoss = 0.004065933252828682: valMetric = 0.0; test_loss = 0.0014493990633499018; testMetric = 0.0
[2023-05-28 12:51:35,844][scr.models_trainer][INFO] - Epoch_10: trainLoss = 0.38381785082588166: valLoss = 0.015986770485576368: valMetric = 0.0; test_loss = 0.003096441773670195; testMetric = 0.0
[2023-05-28 12:56:11,729][scr.models_trainer][INFO] - Epoch_11: trainLoss = 0.39385089067359796: valLoss = 0.004390057736636846: valMetric = 0.0; test_loss = 0.0025881744737509056; testMetric = 0.0
[2023-05-28 13:00:53,518][scr.models_trainer][INFO] - Epoch_12: trainLoss = 0.40400161576323884: valLoss = 0.04174814997568502: valMetric = 0.0; test_loss = 0.011662464333517898; testMetric = 0.0
[2023-05-28 13:05:30,185][scr.models_trainer][INFO] - Epoch_13: trainLoss = 0.4598889263993352: valLoss = 0.2692643264729773: valMetric = 0.0; test_loss = 0.22800043449606947; testMetric = 0.0
[2023-05-28 13:10:05,910][scr.models_trainer][INFO] - Epoch_14: trainLoss = 0.5150040392069204: valLoss = 0.5142016680396382: valMetric = 0.0; test_loss = 0.5141796700416073; testMetric = 0.0
[2023-05-28 13:14:49,194][scr.models_trainer][INFO] - Epoch_15: trainLoss = 0.510241280137348: valLoss = 0.506119318643407: valMetric = 0.0; test_loss = 0.5060962175810209; testMetric = 0.0
[2023-05-28 13:19:26,321][scr.models_trainer][INFO] - Epoch_16: trainLoss = 0.5023979964425328: valLoss = 0.4995762777687916: valMetric = 0.0; test_loss = 0.4995522457425312; testMetric = 0.0
[2023-05-28 13:24:02,280][scr.models_trainer][INFO] - Epoch_17: trainLoss = 0.4988560154219674: valLoss = 0.4987315460665142: valMetric = 0.0; test_loss = 0.4987073902801801; testMetric = 0.0
[2023-05-28 13:28:43,582][scr.models_trainer][INFO] - Epoch_18: trainLoss = 0.498703339638703: valLoss = 0.4987331079178719: valMetric = 0.0; test_loss = 0.49870895346005756; testMetric = 0.0
[2023-05-28 13:33:23,497][scr.models_trainer][INFO] - Epoch_19: trainLoss = 0.4986993159465987: valLoss = 0.498726910382659: valMetric = 0.0; test_loss = 0.498702758742917; testMetric = 0.0
[2023-05-28 13:38:00,548][scr.models_trainer][INFO] - Epoch_20: trainLoss = 0.4986997695405867: valLoss = 0.4987352843859687: valMetric = 0.0; test_loss = 0.4987111341568731; testMetric = 0.0
[2023-05-28 13:42:38,899][scr.models_trainer][INFO] - Epoch_21: trainLoss = 0.49869905093043737: valLoss = 0.4987268304105979: valMetric = 0.0; test_loss = 0.498702682154153; testMetric = 0.0
[2023-05-28 13:47:17,806][scr.models_trainer][INFO] - Epoch_22: trainLoss = 0.4987054997832243: valLoss = 0.49872840019925757: valMetric = 0.0; test_loss = 0.49870424885903636; testMetric = 0.0
[2023-05-28 13:51:54,321][scr.models_trainer][INFO] - Epoch_23: trainLoss = 0.498705021378913: valLoss = 0.49873102175530476: valMetric = 0.0; test_loss = 0.4987068682588557; testMetric = 0.0
[2023-05-28 13:56:31,462][scr.models_trainer][INFO] - Epoch_24: trainLoss = 0.4987012245102154: valLoss = 0.4987336229439357: valMetric = 0.0; test_loss = 0.4987094751609269; testMetric = 0.0
[2023-05-28 14:01:19,744][scr.models_trainer][INFO] - Epoch_25: trainLoss = 0.4986982098446287: valLoss = 0.49872804182258684: valMetric = 0.0; test_loss = 0.49870389026980244; testMetric = 0.0
[2023-05-28 14:06:02,473][scr.models_trainer][INFO] - Epoch_26: trainLoss = 0.4987014093638523: valLoss = 0.49872994917121966: valMetric = 0.0; test_loss = 0.49870579761843525; testMetric = 0.0
[2023-05-28 14:10:44,573][scr.models_trainer][INFO] - Epoch_27: trainLoss = 0.4987013929087443: valLoss = 0.498727027944584: valMetric = 0.0; test_loss = 0.49870287602947605; testMetric = 0.0
[2023-05-28 14:15:31,261][scr.models_trainer][INFO] - Epoch_28: trainLoss = 0.49870537441977725: valLoss = 0.4987295126196128: valMetric = 0.0; test_loss = 0.4987053592358866; testMetric = 0.0
[2023-05-28 14:20:13,636][scr.models_trainer][INFO] - Epoch_29: trainLoss = 0.498703730458523: valLoss = 0.4987211109106265: valMetric = 0.0; test_loss = 0.49869696139007486; testMetric = 0.0
[2023-05-28 14:24:57,528][scr.models_trainer][INFO] - Epoch_30: trainLoss = 0.4986969253953486: valLoss = 0.4987367427528803: valMetric = 0.0; test_loss = 0.4987125903047541; testMetric = 0.0
[2023-05-28 14:29:49,821][scr.models_trainer][INFO] - Epoch_31: trainLoss = 0.49870203154125803: valLoss = 0.49871284892810647: valMetric = 0.0; test_loss = 0.4986886955717558; testMetric = 0.0
[2023-05-28 14:34:37,371][scr.models_trainer][INFO] - Epoch_32: trainLoss = 0.4987014503475482: valLoss = 0.498734060394105: valMetric = 0.0; test_loss = 0.4987099068139189; testMetric = 0.0
[2023-05-28 14:39:21,266][scr.models_trainer][INFO] - Epoch_33: trainLoss = 0.4987034123264352: valLoss = 0.498728696275596: valMetric = 0.0; test_loss = 0.49870454175497897; testMetric = 0.0
[2023-05-28 14:44:10,790][scr.models_trainer][INFO] - Epoch_34: trainLoss = 0.49870519042015077: valLoss = 0.49872582402061577: valMetric = 0.0; test_loss = 0.49870166823428164; testMetric = 0.0
[2023-05-28 14:48:57,321][scr.models_trainer][INFO] - Epoch_35: trainLoss = 0.49869741264791223: valLoss = 0.4987326900863168: valMetric = 0.0; test_loss = 0.49870853879118476; testMetric = 0.0
[2023-05-28 14:53:41,630][scr.models_trainer][INFO] - Epoch_36: trainLoss = 0.4987018608712375: valLoss = 0.4987280993305858: valMetric = 0.0; test_loss = 0.49870394699035153; testMetric = 0.0
[2023-05-28 14:58:35,371][scr.models_trainer][INFO] - Epoch_37: trainLoss = 0.4987014458749988: valLoss = 0.49872762099582346: valMetric = 0.0; test_loss = 0.49870347111455854; testMetric = 0.0
[2023-05-28 15:03:34,851][scr.models_trainer][INFO] - Epoch_38: trainLoss = 0.49870219355671935: valLoss = 0.4987222652638977: valMetric = 0.0; test_loss = 0.4986981105419897; testMetric = 0.0
[2023-05-28 15:08:22,396][scr.models_trainer][INFO] - Epoch_39: trainLoss = 0.49870199613944466: valLoss = 0.4987236896351953: valMetric = 0.0; test_loss = 0.4986995388102788; testMetric = 0.0
[2023-05-28 15:13:11,712][scr.models_trainer][INFO] - Epoch_40: trainLoss = 0.4987034056792407: valLoss = 0.49873123815910303: valMetric = 0.0; test_loss = 0.498707091295591; testMetric = 0.0
[2023-05-28 15:17:57,417][scr.models_trainer][INFO] - Epoch_41: trainLoss = 0.49869980628064325: valLoss = 0.49872994917121966: valMetric = 0.0; test_loss = 0.49870579761843525; testMetric = 0.0
[2023-05-28 15:22:43,927][scr.models_trainer][INFO] - Epoch_42: trainLoss = 0.49870095751310206: valLoss = 0.4987255161132046: valMetric = 0.0; test_loss = 0.49870136924969255; testMetric = 0.0
[2023-05-28 15:27:30,462][scr.models_trainer][INFO] - Epoch_43: trainLoss = 0.4987008847637402: valLoss = 0.49873036535541015: valMetric = 0.0; test_loss = 0.49870621453049363; testMetric = 0.0
[2023-05-28 15:32:21,759][scr.models_trainer][INFO] - Epoch_44: trainLoss = 0.49870328924328394: valLoss = 0.4987317364120004: valMetric = 0.0; test_loss = 0.49870758511686836; testMetric = 0.0
[2023-05-28 15:37:05,305][scr.models_trainer][INFO] - Epoch_45: trainLoss = 0.49870376217136353: valLoss = 0.4987303075478904: valMetric = 0.0; test_loss = 0.49870615620766917; testMetric = 0.0
[2023-05-28 15:41:50,404][scr.models_trainer][INFO] - Epoch_46: trainLoss = 0.49870404886354197: valLoss = 0.49871958575057024: valMetric = 0.0; test_loss = 0.4986954302557053; testMetric = 0.0
[2023-05-28 15:46:42,277][scr.models_trainer][INFO] - Epoch_47: trainLoss = 0.4987030022165448: valLoss = 0.49872450957346204: valMetric = 0.0; test_loss = 0.49870035757300674; testMetric = 0.0
[2023-05-28 15:51:29,263][scr.models_trainer][INFO] - Epoch_48: trainLoss = 0.49870393830000737: valLoss = 0.4987229742296976: valMetric = 0.0; test_loss = 0.49869881970908053; testMetric = 0.0
[2023-05-28 15:56:13,369][scr.models_trainer][INFO] - Epoch_49: trainLoss = 0.4987043919204081: valLoss = 0.49872899549690325: valMetric = 0.0; test_loss = 0.49870484394411885; testMetric = 0.0
[2023-05-28 16:01:04,854][scr.models_trainer][INFO] - Epoch_50: trainLoss = 0.4987059410953099: valLoss = 0.4987217707550106: valMetric = 0.0; test_loss = 0.49869761672071233; testMetric = 0.0
[2023-05-28 16:05:49,798][scr.models_trainer][INFO] - Epoch_51: trainLoss = 0.49870244381698936: valLoss = 0.49873680250728547: valMetric = 0.0; test_loss = 0.49871265022985395; testMetric = 0.0
[2023-05-28 16:10:38,517][scr.models_trainer][INFO] - Epoch_52: trainLoss = 0.4987021036655195: valLoss = 0.4987279816189004: valMetric = 0.0; test_loss = 0.49870382970379246; testMetric = 0.0
[2023-05-28 16:15:30,282][scr.models_trainer][INFO] - Epoch_53: trainLoss = 0.49870441512836133: valLoss = 0.4987263769360643: valMetric = 0.0; test_loss = 0.4987022245442995; testMetric = 0.0
[2023-05-28 16:20:19,891][scr.models_trainer][INFO] - Epoch_54: trainLoss = 0.4987017452012489: valLoss = 0.49872220925350286: valMetric = 0.0; test_loss = 0.4986980531805305; testMetric = 0.0
[2023-05-28 16:25:06,219][scr.models_trainer][INFO] - Epoch_55: trainLoss = 0.498704965269548: valLoss = 0.49873203518402637: valMetric = 0.0; test_loss = 0.4987078818582719; testMetric = 0.0
[2023-05-28 16:29:56,552][scr.models_trainer][INFO] - Epoch_56: trainLoss = 0.498702382970948: valLoss = 0.4987252383076366: valMetric = 0.0; test_loss = 0.4987010859674023; testMetric = 0.0
[2023-05-28 16:34:43,461][scr.models_trainer][INFO] - Epoch_57: trainLoss = 0.4987073622390826: valLoss = 0.498728696275596: valMetric = 0.0; test_loss = 0.49870454175497897; testMetric = 0.0
[2023-05-28 16:39:32,787][scr.models_trainer][INFO] - Epoch_58: trainLoss = 0.49869816872006506: valLoss = 0.4987255969838281: valMetric = 0.0; test_loss = 0.4987014461589116; testMetric = 0.0
[2023-05-28 16:44:26,738][scr.models_trainer][INFO] - Epoch_59: trainLoss = 0.49870635219127424: valLoss = 0.49872146749017227: valMetric = 0.0; test_loss = 0.4986973116474767; testMetric = 0.0
[2023-05-28 16:49:17,602][scr.models_trainer][INFO] - Epoch_60: trainLoss = 0.49870245426761173: valLoss = 0.49872379057371435: valMetric = 0.0; test_loss = 0.49869963718998817; testMetric = 0.0
[2023-05-28 16:54:05,331][scr.models_trainer][INFO] - Epoch_61: trainLoss = 0.49870042112412444: valLoss = 0.4987216121587322: valMetric = 0.0; test_loss = 0.4986974561727175; testMetric = 0.0
[2023-05-28 16:58:52,822][scr.models_trainer][INFO] - Epoch_62: trainLoss = 0.4987000123260645: valLoss = 0.4987242271253212: valMetric = 0.0; test_loss = 0.4987000755725368; testMetric = 0.0
[2023-05-28 17:03:44,369][scr.models_trainer][INFO] - Epoch_63: trainLoss = 0.49870025139615665: valLoss = 0.4987326158051515: valMetric = 0.0; test_loss = 0.4987084650865165; testMetric = 0.0
[2023-05-28 17:08:32,855][scr.models_trainer][INFO] - Epoch_64: trainLoss = 0.49870148308167955: valLoss = 0.4987260742702676: valMetric = 0.0; test_loss = 0.49870192235515964; testMetric = 0.0
[2023-05-28 17:13:24,786][scr.models_trainer][INFO] - Epoch_65: trainLoss = 0.49869837861293526: valLoss = 0.4987179729806718: valMetric = 0.0; test_loss = 0.4986938190075659; testMetric = 0.0
[2023-05-28 17:18:14,862][scr.models_trainer][INFO] - Epoch_66: trainLoss = 0.498701870450241: valLoss = 0.49872363182767554: valMetric = 0.0; test_loss = 0.4986994804874543; testMetric = 0.0
[2023-05-28 17:23:04,362][scr.models_trainer][INFO] - Epoch_67: trainLoss = 0.49870245142384506: valLoss = 0.4987303075478904: valMetric = 0.0; test_loss = 0.49870615620766917; testMetric = 0.0
[2023-05-28 17:27:54,089][scr.models_trainer][INFO] - Epoch_68: trainLoss = 0.4987032250252221: valLoss = 0.4987263769360643: valMetric = 0.0; test_loss = 0.4987022245442995; testMetric = 0.0
[2023-05-28 17:32:46,243][scr.models_trainer][INFO] - Epoch_69: trainLoss = 0.4987011364414914: valLoss = 0.49872804182258684: valMetric = 0.0; test_loss = 0.49870389026980244; testMetric = 0.0
[2023-05-28 17:37:35,979][scr.models_trainer][INFO] - Epoch_70: trainLoss = 0.49870092963010204: valLoss = 0.4987333430417219: valMetric = 0.0; test_loss = 0.498709193160457; testMetric = 0.0
[2023-05-28 17:42:27,635][scr.models_trainer][INFO] - Epoch_71: trainLoss = 0.4987027148024194: valLoss = 0.4987248815783304: valMetric = 0.0; test_loss = 0.49870072705771334; testMetric = 0.0
[2023-05-28 17:47:23,132][scr.models_trainer][INFO] - Epoch_72: trainLoss = 0.4986999567361491: valLoss = 0.4987275443184915: valMetric = 0.0; test_loss = 0.4987033942053395; testMetric = 0.0
[2023-05-28 17:52:13,071][scr.models_trainer][INFO] - Epoch_73: trainLoss = 0.49869943181908466: valLoss = 0.49872450957346204: valMetric = 0.0; test_loss = 0.49870035757300674; testMetric = 0.0
[2023-05-28 17:57:02,242][scr.models_trainer][INFO] - Epoch_74: trainLoss = 0.49870023843632844: valLoss = 0.498719166421411: valMetric = 0.0; test_loss = 0.4986950082163657; testMetric = 0.0
[2023-05-28 18:02:01,297][scr.models_trainer][INFO] - Epoch_75: trainLoss = 0.4987012543125378: valLoss = 0.4987252383076366: valMetric = 0.0; test_loss = 0.4987010859674023; testMetric = 0.0
[2023-05-28 18:06:51,429][scr.models_trainer][INFO] - Epoch_76: trainLoss = 0.49870398605415706: valLoss = 0.4987292932206063: valMetric = 0.0; test_loss = 0.49870513876279193; testMetric = 0.0
[2023-05-28 18:11:36,758][scr.models_trainer][INFO] - Epoch_77: trainLoss = 0.4987031104997835: valLoss = 0.49872480280435266: valMetric = 0.0; test_loss = 0.4987006479053087; testMetric = 0.0
[2023-05-28 18:16:33,421][scr.models_trainer][INFO] - Epoch_78: trainLoss = 0.49870059486682167: valLoss = 0.4987276822478328: valMetric = 0.0; test_loss = 0.49870353232147874; testMetric = 0.0
[2023-05-28 18:21:24,127][scr.models_trainer][INFO] - Epoch_79: trainLoss = 0.4987029937116575: valLoss = 0.49872450957346204: valMetric = 0.0; test_loss = 0.49870035757300674; testMetric = 0.0
[2023-05-28 18:26:15,045][scr.models_trainer][INFO] - Epoch_80: trainLoss = 0.49869956105639346: valLoss = 0.4987184325953824: valMetric = 0.0; test_loss = 0.49869428014242523; testMetric = 0.0
[2023-05-28 18:31:09,350][scr.models_trainer][INFO] - Epoch_81: trainLoss = 0.4987035392570355: valLoss = 0.49872784743356946: valMetric = 0.0; test_loss = 0.4987036967149345; testMetric = 0.0
[2023-05-28 18:35:59,380][scr.models_trainer][INFO] - Epoch_82: trainLoss = 0.49870467623544407: valLoss = 0.4987331685708396: valMetric = 0.0; test_loss = 0.4987090172306184; testMetric = 0.0
[2023-05-28 18:40:49,755][scr.models_trainer][INFO] - Epoch_83: trainLoss = 0.4987020929243575: valLoss = 0.4987276822478328: valMetric = 0.0; test_loss = 0.49870353232147874; testMetric = 0.0
[2023-05-28 18:45:47,874][scr.models_trainer][INFO] - Epoch_84: trainLoss = 0.49870124033141877: valLoss = 0.49872708814827044: valMetric = 0.0; test_loss = 0.49870293659548603; testMetric = 0.0
[2023-05-28 18:50:37,018][scr.models_trainer][INFO] - Epoch_85: trainLoss = 0.4987005631275684: valLoss = 0.4987243460350899: valMetric = 0.0; test_loss = 0.49870019253864084; testMetric = 0.0
[2023-05-28 18:55:33,742][scr.models_trainer][INFO] - Epoch_86: trainLoss = 0.4987022375954835: valLoss = 0.4987252997094063: valMetric = 0.0; test_loss = 0.49870114621295725; testMetric = 0.0
[2023-05-28 19:00:31,654][scr.models_trainer][INFO] - Epoch_87: trainLoss = 0.498699850266582: valLoss = 0.49871713956396785: valMetric = 0.0; test_loss = 0.4986929887084551; testMetric = 0.0
[2023-05-28 19:05:23,346][scr.models_trainer][INFO] - Epoch_88: trainLoss = 0.49870324214064743: valLoss = 0.4987217707550106: valMetric = 0.0; test_loss = 0.49869761672071233; testMetric = 0.0
[2023-05-28 19:10:14,433][scr.models_trainer][INFO] - Epoch_89: trainLoss = 0.49870275105824324: valLoss = 0.49872885457235366: valMetric = 0.0; test_loss = 0.49870470678934486; testMetric = 0.0
[2023-05-28 19:15:12,170][scr.models_trainer][INFO] - Epoch_90: trainLoss = 0.498702246795905: valLoss = 0.49872708814827044: valMetric = 0.0; test_loss = 0.49870293659548603; testMetric = 0.0
[2023-05-28 19:20:03,822][scr.models_trainer][INFO] - Epoch_91: trainLoss = 0.4986979736006947: valLoss = 0.498731678754241: valMetric = 0.0; test_loss = 0.498707527114499; testMetric = 0.0
[2023-05-28 19:24:54,137][scr.models_trainer][INFO] - Epoch_92: trainLoss = 0.4987025766024033: valLoss = 0.49872899549690325: valMetric = 0.0; test_loss = 0.49870484394411885; testMetric = 0.0
[2023-05-28 19:29:42,853][scr.models_trainer][INFO] - Epoch_93: trainLoss = 0.4987028032321169: valLoss = 0.49873447927398296: valMetric = 0.0; test_loss = 0.498710326930528; testMetric = 0.0
[2023-05-28 19:34:38,397][scr.models_trainer][INFO] - Epoch_94: trainLoss = 0.49870316497156153: valLoss = 0.49873114530764634: valMetric = 0.0; test_loss = 0.49870699291588155; testMetric = 0.0
[2023-05-28 19:39:26,291][scr.models_trainer][INFO] - Epoch_95: trainLoss = 0.49870292616559625: valLoss = 0.49872833954628987: valMetric = 0.0; test_loss = 0.4987041850884755; testMetric = 0.0
[2023-05-28 19:44:14,388][scr.models_trainer][INFO] - Epoch_96: trainLoss = 0.49870251123979137: valLoss = 0.4987279816189004: valMetric = 0.0; test_loss = 0.49870382970379246; testMetric = 0.0
[2023-05-28 19:49:07,659][scr.models_trainer][INFO] - Epoch_97: trainLoss = 0.4987023859379739: valLoss = 0.49873477280439443: valMetric = 0.0; test_loss = 0.4987106227105664; testMetric = 0.0
[2023-05-28 19:53:56,819][scr.models_trainer][INFO] - Epoch_98: trainLoss = 0.49870102194246546: valLoss = 0.4987232132473184: valMetric = 0.0; test_loss = 0.4986990613322104; testMetric = 0.0
[2023-05-28 19:58:47,316][scr.models_trainer][INFO] - Epoch_99: trainLoss = 0.49870206539352674: valLoss = 0.4987243460350899: valMetric = 0.0; test_loss = 0.49870019253864084; testMetric = 0.0
[2023-05-28 20:03:40,020][scr.models_trainer][INFO] - Epoch_100: trainLoss = 0.4987005629514838: valLoss = 0.4987216121587322: valMetric = 0.0; test_loss = 0.4986974561727175; testMetric = 0.0
[2023-05-28 20:08:29,139][scr.models_trainer][INFO] - Epoch_101: trainLoss = 0.49870451509160163: valLoss = 0.4987260742702676: valMetric = 0.0; test_loss = 0.49870192235515964; testMetric = 0.0
[2023-05-28 20:13:18,068][scr.models_trainer][INFO] - Epoch_102: trainLoss = 0.4987021106208621: valLoss = 0.49872018044917427: valMetric = 0.0; test_loss = 0.4986960237385124; testMetric = 0.0
[2023-05-28 20:18:09,959][scr.models_trainer][INFO] - Epoch_103: trainLoss = 0.4987004609016407: valLoss = 0.49872738587197346: valMetric = 0.0; test_loss = 0.4987032314141591; testMetric = 0.0
[2023-05-28 20:22:58,071][scr.models_trainer][INFO] - Epoch_104: trainLoss = 0.4987054208709007: valLoss = 0.49872379057371435: valMetric = 0.0; test_loss = 0.49869963718998817; testMetric = 0.0
[2023-05-28 20:27:43,823][scr.models_trainer][INFO] - Epoch_105: trainLoss = 0.4987005490055817: valLoss = 0.4987213115895813: valMetric = 0.0; test_loss = 0.4986971568676733; testMetric = 0.0
[2023-05-28 20:32:36,463][scr.models_trainer][INFO] - Epoch_106: trainLoss = 0.4987036925651122: valLoss = 0.49872450957346204: valMetric = 0.0; test_loss = 0.49870035757300674; testMetric = 0.0
[2023-05-28 20:37:24,825][scr.models_trainer][INFO] - Epoch_107: trainLoss = 0.49870464432010625: valLoss = 0.49873159878217993: valMetric = 0.0; test_loss = 0.498707450525735; testMetric = 0.0
[2023-05-28 20:42:14,626][scr.models_trainer][INFO] - Epoch_108: trainLoss = 0.4986988753036347: valLoss = 0.4987213115895813: valMetric = 0.0; test_loss = 0.4986971568676733; testMetric = 0.0
[2023-05-28 20:47:07,793][scr.models_trainer][INFO] - Epoch_109: trainLoss = 0.49870384904271214: valLoss = 0.498723927904014: valMetric = 0.0; test_loss = 0.49869977338339694; testMetric = 0.0
[2023-05-28 20:51:55,520][scr.models_trainer][INFO] - Epoch_110: trainLoss = 0.4986999392949672: valLoss = 0.4987295711759347: valMetric = 0.0; test_loss = 0.49870541627689075; testMetric = 0.0
[2023-05-28 20:56:45,280][scr.models_trainer][INFO] - Epoch_111: trainLoss = 0.4987012052905788: valLoss = 0.4987210146146803: valMetric = 0.0; test_loss = 0.498696861087635; testMetric = 0.0
[2023-05-28 21:01:38,946][scr.models_trainer][INFO] - Epoch_112: trainLoss = 0.4987033008648691: valLoss = 0.4987258989008228: valMetric = 0.0; test_loss = 0.49870174578441084; testMetric = 0.0
[2023-05-28 21:06:35,446][scr.models_trainer][INFO] - Epoch_113: trainLoss = 0.498702179830923: valLoss = 0.49872582402061577: valMetric = 0.0; test_loss = 0.49870166823428164; testMetric = 0.0
[2023-05-28 21:11:23,972][scr.models_trainer][INFO] - Epoch_114: trainLoss = 0.49870084026715605: valLoss = 0.49872631313812793: valMetric = 0.0; test_loss = 0.4987021598123735; testMetric = 0.0
[2023-05-28 21:16:13,664][scr.models_trainer][INFO] - Epoch_115: trainLoss = 0.4987057746513203: valLoss = 0.4987176172996885: valMetric = 0.0; test_loss = 0.49869346394333786; testMetric = 0.0
[2023-05-28 21:20:58,775][scr.models_trainer][INFO] - Epoch_116: trainLoss = 0.4986991915164001: valLoss = 0.49872349285001133: valMetric = 0.0; test_loss = 0.49869934429404555; testMetric = 0.0
[2023-05-28 21:25:42,923][scr.models_trainer][INFO] - Epoch_117: trainLoss = 0.4986994164733098: valLoss = 0.49872450957346204: valMetric = 0.0; test_loss = 0.49870035757300674; testMetric = 0.0
[2023-05-28 21:30:30,410][scr.models_trainer][INFO] - Epoch_118: trainLoss = 0.4987019733012691: valLoss = 0.4987227783430761: valMetric = 0.0; test_loss = 0.4986986264746676; testMetric = 0.0
[2023-05-28 21:35:22,384][scr.models_trainer][INFO] - Epoch_119: trainLoss = 0.49870425198595847: valLoss = 0.4987295711759347: valMetric = 0.0; test_loss = 0.49870541627689075; testMetric = 0.0
[2023-05-28 21:40:08,224][scr.models_trainer][INFO] - Epoch_120: trainLoss = 0.49870142470962714: valLoss = 0.4987290530049022: valMetric = 0.0; test_loss = 0.49870490066466794; testMetric = 0.0
[2023-05-28 21:44:56,502][scr.models_trainer][INFO] - Epoch_121: trainLoss = 0.49870195803473233: valLoss = 0.4987225658330486: valMetric = 0.0; test_loss = 0.4986984098470339; testMetric = 0.0
[2023-05-28 21:49:50,464][scr.models_trainer][INFO] - Epoch_122: trainLoss = 0.49870244573631173: valLoss = 0.49873233350677104: valMetric = 0.0; test_loss = 0.4987081830860466; testMetric = 0.0
[2023-05-28 21:54:38,531][scr.models_trainer][INFO] - Epoch_123: trainLoss = 0.49870283864273457: valLoss = 0.49872653792850935: valMetric = 0.0; test_loss = 0.49870238509229436; testMetric = 0.0
[2023-05-28 21:59:24,455][scr.models_trainer][INFO] - Epoch_124: trainLoss = 0.4987011724507967: valLoss = 0.4987259567083426: valMetric = 0.0; test_loss = 0.49870180506860057; testMetric = 0.0
[2023-05-28 22:04:13,012][scr.models_trainer][INFO] - Epoch_125: trainLoss = 0.4987049454336152: valLoss = 0.49873131902972656: valMetric = 0.0; test_loss = 0.49870716820481004; testMetric = 0.0
[2023-05-28 22:08:56,889][scr.models_trainer][INFO] - Epoch_126: trainLoss = 0.49870310055980654: valLoss = 0.49873233350677104: valMetric = 0.0; test_loss = 0.4987081830860466; testMetric = 0.0
[2023-05-28 22:13:43,805][scr.models_trainer][INFO] - Epoch_127: trainLoss = 0.49870173191566414: valLoss = 0.49872075298323704: valMetric = 0.0; test_loss = 0.4986966040826613; testMetric = 0.0
[2023-05-28 22:18:31,309][scr.models_trainer][INFO] - Epoch_128: trainLoss = 0.4987022012956385: valLoss = 0.49872726681244434: valMetric = 0.0; test_loss = 0.4987031134866899; testMetric = 0.0
[2023-05-28 22:23:13,799][scr.models_trainer][INFO] - Epoch_129: trainLoss = 0.49870188989878755: valLoss = 0.4987260742702676: valMetric = 0.0; test_loss = 0.49870192235515964; testMetric = 0.0
[2023-05-28 22:28:08,092][scr.models_trainer][INFO] - Epoch_130: trainLoss = 0.4987041617866105: valLoss = 0.4987208921106617: valMetric = 0.0; test_loss = 0.49869674027607; testMetric = 0.0
[2023-05-28 22:32:58,063][scr.models_trainer][INFO] - Epoch_131: trainLoss = 0.4987043561840339: valLoss = 0.49872379057371435: valMetric = 0.0; test_loss = 0.49869963718998817; testMetric = 0.0
[2023-05-28 22:37:41,545][scr.models_trainer][INFO] - Epoch_132: trainLoss = 0.49870380418515453: valLoss = 0.4987256577865562: valMetric = 0.0; test_loss = 0.49870150736583174; testMetric = 0.0
[2023-05-28 22:42:35,539][scr.models_trainer][INFO] - Epoch_133: trainLoss = 0.4987009442099088: valLoss = 0.4987279816189004: valMetric = 0.0; test_loss = 0.49870382970379246; testMetric = 0.0
[2023-05-28 22:47:41,361][scr.models_trainer][INFO] - Epoch_134: trainLoss = 0.4987009104368782: valLoss = 0.4987243460350899: valMetric = 0.0; test_loss = 0.49870019253864084; testMetric = 0.0
[2023-05-28 22:52:28,252][scr.models_trainer][INFO] - Epoch_135: trainLoss = 0.49870432700681194: valLoss = 0.498727027944584: valMetric = 0.0; test_loss = 0.49870287602947605; testMetric = 0.0
[2023-05-28 22:57:11,828][scr.models_trainer][INFO] - Epoch_136: trainLoss = 0.49870498527276114: valLoss = 0.4987256577865562: valMetric = 0.0; test_loss = 0.49870150736583174; testMetric = 0.0
[2023-05-28 23:02:05,874][scr.models_trainer][INFO] - Epoch_137: trainLoss = 0.4986985170594699: valLoss = 0.49872379057371435: valMetric = 0.0; test_loss = 0.49869963718998817; testMetric = 0.0
[2023-05-28 23:06:54,378][scr.models_trainer][INFO] - Epoch_138: trainLoss = 0.4987001460975523: valLoss = 0.49873042615813823: valMetric = 0.0; test_loss = 0.4987062757374138; testMetric = 0.0
[2023-05-28 23:11:39,909][scr.models_trainer][INFO] - Epoch_139: trainLoss = 0.49870416570449333: valLoss = 0.4987232132473184: valMetric = 0.0; test_loss = 0.4986990613322104; testMetric = 0.0
[2023-05-28 23:16:30,041][scr.models_trainer][INFO] - Epoch_140: trainLoss = 0.4987019643385618: valLoss = 0.4987298760881376: valMetric = 0.0; test_loss = 0.4987057242342221; testMetric = 0.0
[2023-05-28 23:21:17,310][scr.models_trainer][INFO] - Epoch_141: trainLoss = 0.49870410347618765: valLoss = 0.49872617670639074: valMetric = 0.0; test_loss = 0.49870202458033; testMetric = 0.0
[2023-05-28 23:26:00,041][scr.models_trainer][INFO] - Epoch_142: trainLoss = 0.4987020991665574: valLoss = 0.4987260742702676: valMetric = 0.0; test_loss = 0.49870192235515964; testMetric = 0.0
[2023-05-28 23:30:44,518][scr.models_trainer][INFO] - Epoch_143: trainLoss = 0.4987028841870222: valLoss = 0.49873769642719673: valMetric = 0.0; test_loss = 0.49871354397907053; testMetric = 0.0
[2023-05-28 23:35:35,838][scr.models_trainer][INFO] - Epoch_144: trainLoss = 0.4986989954637812: valLoss = 0.4987282842846971: valMetric = 0.0; test_loss = 0.49870413189293233; testMetric = 0.0
[2023-05-28 23:40:18,483][scr.models_trainer][INFO] - Epoch_145: trainLoss = 0.49870128699384375: valLoss = 0.49872899549690325: valMetric = 0.0; test_loss = 0.49870484394411885; testMetric = 0.0
[2023-05-28 23:45:05,258][scr.models_trainer][INFO] - Epoch_146: trainLoss = 0.4987026358724873: valLoss = 0.49872738587197346: valMetric = 0.0; test_loss = 0.4987032314141591; testMetric = 0.0
[2023-05-28 23:49:58,379][scr.models_trainer][INFO] - Epoch_147: trainLoss = 0.4987008482085725: valLoss = 0.4987242271253212: valMetric = 0.0; test_loss = 0.4987000755725368; testMetric = 0.0
[2023-05-28 23:54:44,120][scr.models_trainer][INFO] - Epoch_148: trainLoss = 0.49870183472267104: valLoss = 0.4987242271253212: valMetric = 0.0; test_loss = 0.4987000755725368; testMetric = 0.0
[2023-05-28 23:59:26,443][scr.models_trainer][INFO] - Epoch_149: trainLoss = 0.49870241382097386: valLoss = 0.4987263769360643: valMetric = 0.0; test_loss = 0.4987022245442995; testMetric = 0.0
[2023-05-28 23:59:26,443][scr.models_trainer][INFO] - Train losses after 150 epochs : [0.5560465520470674, 0.365868284061353, 0.32543041541225975, 0.32522642182810796, 0.3261922069213063, 0.33015773175298024, 0.33805856910730925, 0.3478122403209636, 0.3580825882921191, 0.37153013622390996, 0.38381785082588166, 0.39385089067359796, 0.40400161576323884, 0.4598889263993352, 0.5150040392069204, 0.510241280137348, 0.5023979964425328, 0.4988560154219674, 0.498703339638703, 0.4986993159465987, 0.4986997695405867, 0.49869905093043737, 0.4987054997832243, 0.498705021378913, 0.4987012245102154, 0.4986982098446287, 0.4987014093638523, 0.4987013929087443, 0.49870537441977725, 0.498703730458523, 0.4986969253953486, 0.49870203154125803, 0.4987014503475482, 0.4987034123264352, 0.49870519042015077, 0.49869741264791223, 0.4987018608712375, 0.4987014458749988, 0.49870219355671935, 0.49870199613944466, 0.4987034056792407, 0.49869980628064325, 0.49870095751310206, 0.4987008847637402, 0.49870328924328394, 0.49870376217136353, 0.49870404886354197, 0.4987030022165448, 0.49870393830000737, 0.4987043919204081, 0.4987059410953099, 0.49870244381698936, 0.4987021036655195, 0.49870441512836133, 0.4987017452012489, 0.498704965269548, 0.498702382970948, 0.4987073622390826, 0.49869816872006506, 0.49870635219127424, 0.49870245426761173, 0.49870042112412444, 0.4987000123260645, 0.49870025139615665, 0.49870148308167955, 0.49869837861293526, 0.498701870450241, 0.49870245142384506, 0.4987032250252221, 0.4987011364414914, 0.49870092963010204, 0.4987027148024194, 0.4986999567361491, 0.49869943181908466, 0.49870023843632844, 0.4987012543125378, 0.49870398605415706, 0.4987031104997835, 0.49870059486682167, 0.4987029937116575, 0.49869956105639346, 0.4987035392570355, 0.49870467623544407, 0.4987020929243575, 0.49870124033141877, 0.4987005631275684, 0.4987022375954835, 0.498699850266582, 0.49870324214064743, 0.49870275105824324, 0.498702246795905, 0.4986979736006947, 0.4987025766024033, 0.4987028032321169, 0.49870316497156153, 0.49870292616559625, 0.49870251123979137, 0.4987023859379739, 0.49870102194246546, 0.49870206539352674, 0.4987005629514838, 0.49870451509160163, 0.4987021106208621, 0.4987004609016407, 0.4987054208709007, 0.4987005490055817, 0.4987036925651122, 0.49870464432010625, 0.4986988753036347, 0.49870384904271214, 0.4986999392949672, 0.4987012052905788, 0.4987033008648691, 0.498702179830923, 0.49870084026715605, 0.4987057746513203, 0.4986991915164001, 0.4986994164733098, 0.4987019733012691, 0.49870425198595847, 0.49870142470962714, 0.49870195803473233, 0.49870244573631173, 0.49870283864273457, 0.4987011724507967, 0.4987049454336152, 0.49870310055980654, 0.49870173191566414, 0.4987022012956385, 0.49870188989878755, 0.4987041617866105, 0.4987043561840339, 0.49870380418515453, 0.4987009442099088, 0.4987009104368782, 0.49870432700681194, 0.49870498527276114, 0.4986985170594699, 0.4987001460975523, 0.49870416570449333, 0.4987019643385618, 0.49870410347618765, 0.4987020991665574, 0.4987028841870222, 0.4986989954637812, 0.49870128699384375, 0.4987026358724873, 0.4987008482085725, 0.49870183472267104, 0.49870241382097386]
[2023-05-28 23:59:26,444][scr.models_trainer][INFO] - Validation losses after 150 epochs : [0.005861521322524699, 0.0049021189698034515, 0.002745065971259519, 0.005506836893458163, 0.0031738489001624324, 0.0027164729253854603, 0.00314520945525073, 0.0062653290413655855, 0.005147626421247005, 0.004065933252828682, 0.015986770485576368, 0.004390057736636846, 0.04174814997568502, 0.2692643264729773, 0.5142016680396382, 0.506119318643407, 0.4995762777687916, 0.4987315460665142, 0.4987331079178719, 0.498726910382659, 0.4987352843859687, 0.4987268304105979, 0.49872840019925757, 0.49873102175530476, 0.4987336229439357, 0.49872804182258684, 0.49872994917121966, 0.498727027944584, 0.4987295126196128, 0.4987211109106265, 0.4987367427528803, 0.49871284892810647, 0.498734060394105, 0.498728696275596, 0.49872582402061577, 0.4987326900863168, 0.4987280993305858, 0.49872762099582346, 0.4987222652638977, 0.4987236896351953, 0.49873123815910303, 0.49872994917121966, 0.4987255161132046, 0.49873036535541015, 0.4987317364120004, 0.4987303075478904, 0.49871958575057024, 0.49872450957346204, 0.4987229742296976, 0.49872899549690325, 0.4987217707550106, 0.49873680250728547, 0.4987279816189004, 0.4987263769360643, 0.49872220925350286, 0.49873203518402637, 0.4987252383076366, 0.498728696275596, 0.4987255969838281, 0.49872146749017227, 0.49872379057371435, 0.4987216121587322, 0.4987242271253212, 0.4987326158051515, 0.4987260742702676, 0.4987179729806718, 0.49872363182767554, 0.4987303075478904, 0.4987263769360643, 0.49872804182258684, 0.4987333430417219, 0.4987248815783304, 0.4987275443184915, 0.49872450957346204, 0.498719166421411, 0.4987252383076366, 0.4987292932206063, 0.49872480280435266, 0.4987276822478328, 0.49872450957346204, 0.4987184325953824, 0.49872784743356946, 0.4987331685708396, 0.4987276822478328, 0.49872708814827044, 0.4987243460350899, 0.4987252997094063, 0.49871713956396785, 0.4987217707550106, 0.49872885457235366, 0.49872708814827044, 0.498731678754241, 0.49872899549690325, 0.49873447927398296, 0.49873114530764634, 0.49872833954628987, 0.4987279816189004, 0.49873477280439443, 0.4987232132473184, 0.4987243460350899, 0.4987216121587322, 0.4987260742702676, 0.49872018044917427, 0.49872738587197346, 0.49872379057371435, 0.4987213115895813, 0.49872450957346204, 0.49873159878217993, 0.4987213115895813, 0.498723927904014, 0.4987295711759347, 0.4987210146146803, 0.4987258989008228, 0.49872582402061577, 0.49872631313812793, 0.4987176172996885, 0.49872349285001133, 0.49872450957346204, 0.4987227783430761, 0.4987295711759347, 0.4987290530049022, 0.4987225658330486, 0.49873233350677104, 0.49872653792850935, 0.4987259567083426, 0.49873131902972656, 0.49873233350677104, 0.49872075298323704, 0.49872726681244434, 0.4987260742702676, 0.4987208921106617, 0.49872379057371435, 0.4987256577865562, 0.4987279816189004, 0.4987243460350899, 0.498727027944584, 0.4987256577865562, 0.49872379057371435, 0.49873042615813823, 0.4987232132473184, 0.4987298760881376, 0.49872617670639074, 0.4987260742702676, 0.49873769642719673, 0.4987282842846971, 0.49872899549690325, 0.49872738587197346, 0.4987242271253212, 0.4987242271253212, 0.4987263769360643]
[2023-05-28 23:59:26,445][scr.models_trainer][INFO] - Validation metrics in 150 epochs : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[2023-05-28 23:59:26,446][scr.models_trainer][INFO] - Test losses after 150 epochs : [0.002249801598560636, 0.0035559257526221054, 0.0021709717593596427, 0.004332310653426835, 0.0015720960869383747, 0.001576568050246175, 0.002309949409062674, 0.004807981943789248, 0.0040456208150698655, 0.0014493990633499018, 0.003096441773670195, 0.0025881744737509056, 0.011662464333517898, 0.22800043449606947, 0.5141796700416073, 0.5060962175810209, 0.4995522457425312, 0.4987073902801801, 0.49870895346005756, 0.498702758742917, 0.4987111341568731, 0.498702682154153, 0.49870424885903636, 0.4987068682588557, 0.4987094751609269, 0.49870389026980244, 0.49870579761843525, 0.49870287602947605, 0.4987053592358866, 0.49869696139007486, 0.4987125903047541, 0.4986886955717558, 0.4987099068139189, 0.49870454175497897, 0.49870166823428164, 0.49870853879118476, 0.49870394699035153, 0.49870347111455854, 0.4986981105419897, 0.4986995388102788, 0.498707091295591, 0.49870579761843525, 0.49870136924969255, 0.49870621453049363, 0.49870758511686836, 0.49870615620766917, 0.4986954302557053, 0.49870035757300674, 0.49869881970908053, 0.49870484394411885, 0.49869761672071233, 0.49871265022985395, 0.49870382970379246, 0.4987022245442995, 0.4986980531805305, 0.4987078818582719, 0.4987010859674023, 0.49870454175497897, 0.4987014461589116, 0.4986973116474767, 0.49869963718998817, 0.4986974561727175, 0.4987000755725368, 0.4987084650865165, 0.49870192235515964, 0.4986938190075659, 0.4986994804874543, 0.49870615620766917, 0.4987022245442995, 0.49870389026980244, 0.498709193160457, 0.49870072705771334, 0.4987033942053395, 0.49870035757300674, 0.4986950082163657, 0.4987010859674023, 0.49870513876279193, 0.4987006479053087, 0.49870353232147874, 0.49870035757300674, 0.49869428014242523, 0.4987036967149345, 0.4987090172306184, 0.49870353232147874, 0.49870293659548603, 0.49870019253864084, 0.49870114621295725, 0.4986929887084551, 0.49869761672071233, 0.49870470678934486, 0.49870293659548603, 0.498707527114499, 0.49870484394411885, 0.498710326930528, 0.49870699291588155, 0.4987041850884755, 0.49870382970379246, 0.4987106227105664, 0.4986990613322104, 0.49870019253864084, 0.4986974561727175, 0.49870192235515964, 0.4986960237385124, 0.4987032314141591, 0.49869963718998817, 0.4986971568676733, 0.49870035757300674, 0.498707450525735, 0.4986971568676733, 0.49869977338339694, 0.49870541627689075, 0.498696861087635, 0.49870174578441084, 0.49870166823428164, 0.4987021598123735, 0.49869346394333786, 0.49869934429404555, 0.49870035757300674, 0.4986986264746676, 0.49870541627689075, 0.49870490066466794, 0.4986984098470339, 0.4987081830860466, 0.49870238509229436, 0.49870180506860057, 0.49870716820481004, 0.4987081830860466, 0.4986966040826613, 0.4987031134866899, 0.49870192235515964, 0.49869674027607, 0.49869963718998817, 0.49870150736583174, 0.49870382970379246, 0.49870019253864084, 0.49870287602947605, 0.49870150736583174, 0.49869963718998817, 0.4987062757374138, 0.4986990613322104, 0.4987057242342221, 0.49870202458033, 0.49870192235515964, 0.49871354397907053, 0.49870413189293233, 0.49870484394411885, 0.4987032314141591, 0.4987000755725368, 0.4987000755725368, 0.4987022245442995]
[2023-05-28 23:59:26,446][scr.models_trainer][INFO] - Test metrics in 150 epochs : [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
