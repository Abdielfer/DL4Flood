{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abfernan\\CrossCanFloodMapping\\DL4Flood\\scr\\losses.py:197: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if (classes is 'present') and (fg.sum()==0):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/abdielfer/RNCanWork/DL4Flood/')\n",
    "from model_set.models import UNetFlood\n",
    "from scr import util as U\n",
    "from scr import dataLoader as D\n",
    "from scr import models_trainer\n",
    "from scr import losses as L\n",
    "from scr.losses import iou_binary,binaryAccuracy\n",
    "from rasterio.plot import show\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam, SGD\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input \n",
      " tensor([[[ 0.7608, -0.9526,  0.5575,  0.5136, -0.5165],\n",
      "         [-1.3394, -0.2222,  0.1584, -0.7803,  0.2345],\n",
      "         [ 1.1675, -0.4158,  0.3734, -1.4838, -1.5231],\n",
      "         [-1.7897, -0.1309,  0.1922,  0.8222,  2.4470],\n",
      "         [ 0.5046,  0.9268, -0.4107,  0.7975,  1.7679]]])\n",
      "Sigmoid \n",
      " tensor([[[0.6815, 0.5000, 0.6359, 0.6256, 0.5000],\n",
      "         [0.5000, 0.5000, 0.5395, 0.5000, 0.5584],\n",
      "         [0.7627, 0.5000, 0.5923, 0.5000, 0.5000],\n",
      "         [0.5000, 0.5000, 0.5479, 0.6947, 0.9203],\n",
      "         [0.6235, 0.7164, 0.5000, 0.6894, 0.8542]]])\n"
     ]
    }
   ],
   "source": [
    "# Testin nn.softmax2D()\n",
    "input = torch.randn(1,5, 5)\n",
    "# m = nn.Softmax2d()\n",
    "# # you softmax over the 2nd dimension\n",
    "print(\"Input\",\"\\n\", input)\n",
    "# output = m(input)\n",
    "# print(\"Softmax\",output)\n",
    "# print(\"Argmax\",torch.argmax(output, dim=0))\n",
    "S = nn.Sigmoid()\n",
    "print(\"Sigmoid\",\"\\n\",S(input).clamp(0.499999))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signes : [-1. -1.  1.  1.]\n",
      "Errors: [1. 2. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "labels = numpy.array([0,0,1,1])\n",
    "logits = numpy.array([0,1,0,1])\n",
    "signs = 2. * labels- 1.\n",
    "print(f\"Signes : {signs}\")\n",
    "\n",
    "print(f\"Errors: {1. - logits * signs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building *.scv files with imag-mask pair path.  (OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\RawData\\Class5\n",
      "Creating CSV at C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\RawData\\Class5RawDataTest.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesPath = os.path.join(r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\RawData\\Class5') \n",
    "pairImgMaskList = U.makeTifGpkgPairsList(filesPath)\n",
    "csvPath = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\RawData\\Class5RawDataTest.csv'\n",
    "U.createCSVFromList(csvPath,pairImgMaskList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "For sampling we consider all patches target as training \"trn\". Sinse all regions are toguether, to ensure representativity into the test set, the samping is made by region in proportions of 90% training and 10 % test by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\Percentage_1\\fulTrainingSet.csv'\n",
    "out = U.createListFromCSV(csv)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# enter the *.csv containing all pairs image-mask \\\n",
    "csv = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\Percentage_1\\TrainingDataSource_Percentage_1_feat1_min-annot1_trn.csv'\n",
    "\n",
    "def splitPerRegion(csvPath, tstFrac:float = .9)->list:\n",
    "    fullList = U.createListFromCSV(csvPath) \n",
    "    imagList = U.createListFromCSVColumn(csvPath,0,delim=';')\n",
    "    lenimagList = len(imagList)\n",
    "    print(\"Total samples >>\", len(imagList))\n",
    "    parent,name,ext = U.get_parenPath_name_ext(imagList[0])\n",
    "    start = parent\n",
    "    print(f\"First assignement: {start != parent} >> {start}>{parent}\")\n",
    "    print(f\"{start != parent} >> {start}>{parent}\")\n",
    "    regionCounter = 0\n",
    "    lastParent,lastName,_ = U.get_parenPath_name_ext(imagList[-1])\n",
    "    allPath = []\n",
    "    trn = []\n",
    "    tst = []\n",
    "    i = 0\n",
    "    cumulative = 0 \n",
    "    while start == parent:\n",
    "        parent,name,_ = U.get_parenPath_name_ext(imagList[i])\n",
    "        if start != parent:\n",
    "            regionCounter+=1\n",
    "            trnToAdd, tstToAdd = distrubutePathInTrnTst(allPath,tstFrac)\n",
    "            trn.extend(trnToAdd)\n",
    "            tst.extend(tstToAdd)\n",
    "            print(f\"Training set evolution : {len(trn)} vs Teste set {len(tst)} >> Total {len(trn)+len(tst)}\")\n",
    "            print(\"_____________________________\")\n",
    "            start = parent\n",
    "            allPath = []\n",
    "            if start == lastParent:\n",
    "                regionCounter+=1\n",
    "                \n",
    "                allPath = imagList[i:-1]\n",
    "                trnToAdd, tstToAdd = distrubutePathInTrnTst(allPath,tstFrac)\n",
    "                trn.extend(trnToAdd)\n",
    "                tst.extend(tstToAdd)\n",
    "                print(f\"Training set evolution : {len(trn)} vs Teste set {len(tst)} >> Total {len(trn)+len(tst)}\")\n",
    "                print(f\"We sampled {regionCounter} regions\")\n",
    "                print('End of split process')\n",
    "                break\n",
    "            continue\n",
    "        allPath.append(fullList[i])\n",
    "        i +=1\n",
    "        if i == lenimagList: break\n",
    "    return trn,tst\n",
    "\n",
    "def distrubutePathInTrnTst(allPath,trnPercent)->list:\n",
    "    trnPErcent = int(len(allPath)*.9)\n",
    "    srandomSamples = U.randomSamplingFromList(allPath,trnPErcent) \n",
    "    trn, tst = [],[]\n",
    "    for item in srandomSamples:\n",
    "        trn.append(allPath.pop(allPath.index(item)))\n",
    "    tst = allPath\n",
    "    return trn,tst\n",
    "\n",
    "\n",
    "trainList, testList = splitPerRegion(csv)\n",
    "\n",
    "print(len(trainList))\n",
    "print(len(testList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to save\n",
    "trainSetList = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\Percentage_1\\SplitedTrainingSet_test.csv'\n",
    "valSetList = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\Percentage_1\\SplitedValSet_tets.csv'\n",
    "\n",
    "#CSV creation from list\n",
    "U.createCSVFromList(trainSetList, trainList)\n",
    "U.createCSVFromList(valSetList,testList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying data agmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transfer images by copy  ( OK )\n",
    "img_list, mask_list = D.createImageMaskList(scvPath)\n",
    "for i, m in zip(img_list, mask_list):\n",
    "    U.makeFileCopy(i,saveImgDir)\n",
    "    U.makeFileCopy(m,saveMaskDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.plot import show\n",
    "saveDir = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\template_project\\val\\Rotated'\n",
    "scvPath = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\template_project\\val\\listToTransform.csv'\n",
    "img, mask = fullSet.__getitem__(3)\n",
    "print(type(img))\n",
    "# show(img)\n",
    "# show(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In data agmentation- Make permanent transformations.\n",
    "The permanent transformation is applied to the final trainig set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scvPath = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\Percentage_1\\Percentage_1_feat1_min-annot5_trn.csv'\n",
    "Dir = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\Percentage_1\\trn\\rotated180TrnSet'\n",
    "D.offlineTransformation(trainSetList, Dir)\n",
    "\n",
    "#NOTE: The first element in the scv list must be remouved. NO idea Why. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing train cycle  ( OK )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalistPath = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\Percentage_1\\Percentage_1_feat1_min-annot5_trn_PlussRotated.csv'\n",
    "\n",
    "# NOTE: We need to put r in front of the string, to denote raw string. Otherwise,'_' character will truncate the string \n",
    "args = {'batch_size': 1, 'num_workers': 4,'drop_last': True}\n",
    "\n",
    "fullSet = D.customDataSet(datalistPath)\n",
    "# img,mask=fullSet.__getitem__()\n",
    "trainSet, valSet = D.splitDataset(fullSet)\n",
    "print(f\"Dataset lens : train: {trainSet.__len__()} :-- valSet: {valSet.__len__()}\")\n",
    "\n",
    "train_set = D.customDataloader(trainSet,args)  #.getDataloader()     \n",
    "val_set = D.customDataloader(valSet,args)  #.getDataloader()\n",
    "# rasterPath = '/Users/abdielfer/RNCanWork/GDLData/TestTiling/template_project/trn/VilleGatineau-1/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetFlood(1,1)\n",
    "# loss_fn = nn.CrossEntropyLoss() if model.classes > 1 else nn.BCEWithLogitsLoss()\n",
    "loss_fn = L.lovasz_hinge\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr = 0.001) #SGD(model.parameters(), lr=0.001, momentum=0.9)##  \n",
    "\n",
    "trainer = models_trainer.models_trainer(model,loss_fn,optimizer, iou_binary)\n",
    "trainer.set_loaders(train_set,val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with U.timeit():\n",
    "    trainer.train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.load_checkpoint('2304061151')\n",
    "id = U.makeNameByTime()\n",
    "U.saveModel(model, id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing metric computation (OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import sigmoid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _computeMetricPerMiniBatch(data_loader, metric_fn, model):\n",
    "        '''\n",
    "        Return de mean per batch of the metric in self.metric  \n",
    "        '''\n",
    "        metrics = []\n",
    "        miniBathcMetric = []\n",
    "        for x_batch, y_batch in data_loader:\n",
    "            metric=[]\n",
    "            print(f\"Batch = {i}\")\n",
    "            i+=1\n",
    "            for x,y in zip(x_batch, y_batch):\n",
    "                yHat = model(torch.unsqueeze(x,0))\n",
    "                y_hat_sigmoid = torch.round(sigmoid(yHat)).to(torch.int32)\n",
    "                y_item= y.numpy() if torch.is_tensor(y) else y.numpy().squeeze()\n",
    "                y_hat_item = y_hat_sigmoid.detach().numpy().squeeze() if torch.is_tensor(y_hat_sigmoid) else y_hat_sigmoid.numpy().squeeze()\n",
    "                metricPerImage = metric_fn(y_hat_item, y_item)\n",
    "                metric.append(metricPerImage)    \n",
    "            ItemMetric = Average(metric)\n",
    "            miniBathcMetric.append(ItemMetric)\n",
    "        metricMean = Average(miniBathcMetric)\n",
    "        return metricMean\n",
    "\n",
    "def plotImageAndMask(img, img1,mask,imgName:str='Image', img1Name:str='Image1', mskName: str= 'Mask'):\n",
    "    # colList = ['Image','Mask']\n",
    "    image = img.detach().numpy() if torch.is_tensor(img) else img.numpy().squeeze()\n",
    "    image1 = img1.detach().numpy() if torch.is_tensor(img1) else img1.numpy().squeeze()\n",
    "    mask_squeezed = mask.detach().numpy() if torch.is_tensor(mask) else mask.numpy().squeeze()\n",
    "    fig, axs = plt.subplots(1,3, figsize=(10,5), sharey=True)\n",
    "    axs[0].imshow(image, cmap='Greys_r')\n",
    "    axs[0].set(xlabel= imgName)\n",
    "    axs[1].imshow(image1, cmap='Greys_r')\n",
    "    axs[1].set(xlabel= img1Name)\n",
    "    axs[2].imshow(mask_squeezed, cmap='Greys_r')\n",
    "    axs[2].set(xlabel= mskName)\n",
    "    plt.rcParams['font.size'] = '15'\n",
    "    fig.tight_layout()\n",
    "    pass\n",
    "\n",
    "def Average(lst):\n",
    "    ave = sum(lst) / len(lst)\n",
    "    return round(ave,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fn = L.iou_binary\n",
    "model = trainer.getModel()\n",
    "with torch.no_grad():\n",
    "    metric = _computeMetricPerMiniBatch(val_set, metric_fn, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F\"Final matric value {metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = next(iter(val_set))\n",
    "imag = item[0]\n",
    "mask = item[1]\n",
    "print('image to model input shape',imag.shape)\n",
    "\n",
    "model.eval()\n",
    "Y_hat = model(imag)\n",
    "print('Y_hat to model input shape',Y_hat.shape)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,imag.shape[0]):\n",
    "    U.plotImageAndMask(Y_hat[i][0], mask[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Works well!\n",
    "# Testing util.makePredictionRaster() for inference.\n",
    "inToInfer,_ = U.readRaster(rasterPath)\n",
    "\n",
    "imgToInferTensor = U.imageToTensor(inToInfer)\n",
    "print(\"imgToInferTensor shape: ----\", imgToInferTensor.shape)\n",
    "out = U.makePredictionRaster(rasterPath, model,saveRaster=True)\n",
    "print('out shape: _____ ',out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing IoU in modified mask (OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test IoU\n",
    "# Modified mask: righ up corner have been removed from real mask in QGIS. Both share CRS, resolution, ect. \n",
    "parentDir = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\RawData\\SyntheticPredictionandMask'\n",
    "realMask = 'mask1.tif'\n",
    "modifiedMask = 'SintheticGT1_1.tif'\n",
    "\n",
    "maskPath = os.path.join(parentDir,realMask)\n",
    "gtPath = os.path.join(parentDir, modifiedMask)\n",
    "print(maskPath, gtPath)\n",
    "\n",
    "real,_ = U.readRaster(maskPath)\n",
    "modified,_ = U.readRaster(gtPath)\n",
    "\n",
    "ioUB = iou_binary(real,modified)\n",
    "print(f\"iou_binary : {ioUB}\")\n",
    "\n",
    "realTensor = U.imageToTensor(real)\n",
    "modifiedTensor = U.imageToTensor(modified)\n",
    "\n",
    "print(f\"binaryAccuracy : {binaryAccuracy(realTensor,modifiedTensor)}\")\n",
    "\n",
    "U.plotImageAndMask(U.imageToTensor(real)[0],U.imageToTensor(modified)[0],'original mask','modified mask')\n",
    "\n",
    "#  OUTPUT = 87,987% iou, is a good representation of mask differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.plotImageAndMask(imgToInferTensor[0],rasterData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flated = Y_hat[0][0].view(-1)\n",
    "signs = 2. * Y_hat[0][0].float() - 1.\n",
    "# print(Y_hat[0][0][0:20,340:350])\n",
    "# print('signe : ____',signs[0:20,340:350])\n",
    "# print(signs.shape)\n",
    "zerosAndOnes = torch.where(signs==-1,torch.tensor(0),signs)\n",
    "# print(zerosAndOnes[0:20,340:350])\n",
    "errors = (1. - Y_hat[0][0] * Variable(signs))\n",
    "U.plotImageAndMask(Y_hat[0][0], zerosAndOnes)\n",
    "ioUB = L.iou_binary(zerosAndOnes,zerosAndOnes, per_image=False)\n",
    "print(ioUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####   Apply sigmoid to the output image to compare with Mask...IMportant!!!!\n",
    "y_hatSigmoided = torch.sigmoid(Y_hat[0][0])\n",
    "U.plotImageAndMask(y_hatSigmoided, mask[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize all batch image-mask pairs. \n",
    "# NOTE :   img, mask = next(iter(train_set))\n",
    "i = 0\n",
    "j = 0\n",
    "for batch in train_set:\n",
    "    for item in batch:\n",
    "        print(f\"Bathc {i}, item {j}\")\n",
    "        print('item',item.shape)\n",
    "        j +=1\n",
    "        \n",
    "    # U.plotImageAndMask(batch[0][0],batch[1][0])\n",
    "    i+=1\n",
    "    j=0  \n",
    "    print(\"_______\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to test: \n",
    "## Image visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ref: \n",
    "\n",
    "from typing import Iterable, List\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_imgs(images: Iterable, axs: Iterable, chnls: List[int] = [2, 1, 0], bright: float = 3.):\n",
    "    for img, ax in zip(images, axs):\n",
    "        arr = torch.clamp(bright * img, min=0, max=1).numpy()\n",
    "        rgb = arr.transpose(1, 2, 0)[:, :, chnls]\n",
    "        ax.imshow(rgb)\n",
    "        ax.axis('off')\n",
    "\n",
    "\n",
    "def plot_msks(masks: Iterable, axs: Iterable):\n",
    "    for mask, ax in zip(masks, axs):\n",
    "        ax.imshow(mask.squeeze().numpy(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "def plot_batch(batch: dict, bright: float = 3., cols: int = 4, width: int = 5, chnls: List[int] = [2, 1, 0]):\n",
    "\n",
    "    # Get the samples and the number of items in the batch\n",
    "    samples = unbind_samples(batch.copy())\n",
    "    \n",
    "    # if batch contains images and masks, the number of images will be doubled\n",
    "    n = 2 * len(samples) if ('image' in batch) and ('mask' in batch) else len(samples)\n",
    "\n",
    "    # calculate the number of rows in the grid\n",
    "    rows = n//cols + (1 if n%cols != 0 else 0)\n",
    "\n",
    "    # create a grid\n",
    "    _, axs = plt.subplots(rows, cols, figsize=(cols*width, rows*width))  \n",
    "\n",
    "    if ('image' in batch) and ('mask' in batch):\n",
    "        # plot the images on the even axis\n",
    "        plot_imgs(images=map(lambda x: x['image'], samples), axs=axs.reshape(-1)[::2], chnls=chnls, bright=bright) #type: ignore\n",
    "\n",
    "        # plot the masks on the odd axis\n",
    "        plot_msks(masks=map(lambda x: x['mask'], samples), axs=axs.reshape(-1)[1::2]) #type: ignore\n",
    "\n",
    "    else:\n",
    "\n",
    "        if 'image' in batch:\n",
    "            plot_imgs(images=map(lambda x: x['image'], samples), axs=axs.reshape(-1), chnls=chnls, bright=bright) #type: ignore\n",
    "    \n",
    "        elif 'mask' in batch:\n",
    "            plot_msks(masks=map(lambda x: x['mask'], samples), axs=axs.reshape(-1)) #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import  Path\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root = Path('dset-s2')\n",
    "assert root.exists()\n",
    "\n",
    "train_imgs = list((root/'tra_scene').glob('*.tif'))\n",
    "train_masks = list((root/'tra_truth').glob('*.tif'))\n",
    "\n",
    "# As the images and corresponding masks are matched by name, we will sort both lists to keep them synchronized.\n",
    "train_imgs.sort(); train_masks.sort()\n",
    "     \n",
    "\n",
    "idx = 0\n",
    "img = xr.open_rasterio(train_imgs[idx])\n",
    "mask = xr.open_rasterio(train_masks[idx])\n",
    "_, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# plot the tile\n",
    "rgb = img.data[[2, 1, 0]].transpose((1, 2, 0))/3000\n",
    "axs[0].imshow(rgb.clip(min=0, max=1))\n",
    "\n",
    "# plot the mask\n",
    "axs[1].imshow(mask.data.squeeze(), cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning sampling from GDL.  (OK)\n",
    "### GDL sampling includes images with no mask matching. In this section we remove unnecessary files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-recorrer el directorio y crear lista de todos los *.tif. 2-importar *.csv list of images and mask.\n",
    "# 3-compara cada nombre en la lista de *.tif con los de la lista from *.csv, 4- si no esta en la lista, borrar.\n",
    "scvPath = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\Percentage_1\\Percentage_1_feat1_min-annot5_trn.csv'\n",
    "imagDir = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\Percentage_1\\trn'\n",
    "Dir = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\Percentage_1\\trn'\n",
    "\n",
    "# tifList = U.listALLFilesInDirByExt(Dir, ext='.tif')\n",
    "# print(f\"Jupyter Nbk All available *tif :  {len(tifList)}\")\n",
    "noMatchList = U.noMatch_TifMask_List(scvPath,imagDir,relocate = True, relocatePath = Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagDir = r'C:\\Users\\abfernan\\CrossCanFloodMapping\\DatasetCNNFlood\\C1Dataset\\Done\\template_project\\trn'\n",
    "tifList = U.listALLFilesInDirByExt_fullPath(imagDir, ext='.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"tifList list len {len(tifList)}\")\n",
    "print(tifList[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check in for Operative System  (.OK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "def getPlatform():\n",
    "    OPS = ''\n",
    "    if platform == \"darwin\":\n",
    "        OPS = \"mac\"\n",
    "    elif platform == \"win32\":\n",
    "        OPS = \"win\"\n",
    "    return OPS \n",
    "\n",
    "####   \n",
    "\n",
    "OPS = getPlatform()\n",
    "\n",
    "if OPS == 'mac': \n",
    "    configPath = 'config\\configMac.yaml'\n",
    "elif OPS == 'win':\n",
    "    configPath = 'config\\configPC.yaml'\n",
    "\n",
    "print(OPS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "11f83c78310818a0c6ae0b43a5d79327a506e418107ba86e7368dd35fada134d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
